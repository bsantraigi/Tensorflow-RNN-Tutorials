{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !wget \"http://www.cfilt.iitb.ac.in/iitb_parallel/iitb_corpus_download/parallel.tgz\" -P data\n",
    "# !tar -xf data/parallel.tgz -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bishal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE = 10000\n",
    "VH = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, counter, vocab_size):\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.pad = \"<PAD>\"\n",
    "        self.sos = \"<SOS>\"\n",
    "        self.eos = \"<EOS>\"\n",
    "        self.unk = \"<UNK>\"\n",
    "        \n",
    "        self.ipad = 0\n",
    "        self.isos = 1\n",
    "        self.ieos = 2\n",
    "        self.iunk = 3\n",
    "        \n",
    "        self.word2id[self.pad] = 0\n",
    "        self.word2id[self.sos] = 1\n",
    "        self.word2id[self.eos] = 2\n",
    "        self.word2id[self.unk] = 3\n",
    "        \n",
    "        self.id2word[0] = self.pad\n",
    "        self.id2word[1] = self.sos\n",
    "        self.id2word[2] = self.eos\n",
    "        self.id2word[3] = self.unk\n",
    "        \n",
    "        curr_id = 4\n",
    "        for w, c in counter.most_common(vocab_size):\n",
    "            self.word2id[w] = curr_id\n",
    "            self.id2word[curr_id] = w\n",
    "            curr_id += 1\n",
    "            \n",
    "    def encodeSentence(self, s, max_len=-1):\n",
    "        wseq = nltk.tokenize.word_tokenize(s.lower().strip())\n",
    "        if max_len == -1:\n",
    "            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n",
    "        else:\n",
    "            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "        \n",
    "    def encodeSentence2(self, s, max_len=-1):\n",
    "        wseq = nltk.tokenize.word_tokenize(s.lower().strip()) \n",
    "        return min(max_len, len(wseq)), \\\n",
    "            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n",
    "                [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "    \n",
    "    def decodeSentence(self, id_seq):\n",
    "        id_seq = np.array(id_seq + [self.ieos])\n",
    "        j = np.argmax(id_seq==self.ieos)\n",
    "        s = ' '.join([self.id2word[x] for x in id_seq[:j]])\n",
    "        s = s.replace(self.unk, \"UNK\")\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200000\n",
    "# N = 1561840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7332bdd57874bdc94a9571a7bd4122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading file:', max=1561840, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2233c96926946a2b30f4b2950f0a882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=200000, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hi_counter = Counter()\n",
    "hi_sentences=[]\n",
    "with open(\"data/parallel/IITB.en-hi.hi\") as f:\n",
    "    for line in tqdm_notebook(f, total=1561840, desc=\"Reading file:\"):\n",
    "        hi_sentences.append(line.strip())\n",
    "    for line in tqdm_notebook(hi_sentences[:N], desc=\"Processing inputs:\"):\n",
    "        # hi_sentences.append(line.strip())\n",
    "        for w in nltk.tokenize.word_tokenize(line.strip()):\n",
    "            hi_counter[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 36555),\n",
       " ('(', 35172),\n",
       " (')', 35134),\n",
       " ('के', 25558),\n",
       " ('%', 24045),\n",
       " ('है', 23951),\n",
       " ('_', 22906),\n",
       " ('में', 19818),\n",
       " ('को', 17586),\n",
       " ('करें', 17529)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37175\n"
     ]
    }
   ],
   "source": [
    "print(len(hi_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc148ef1447481682aa288f82d7121f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading file:', max=1561840, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9977b982388d495dbe99b18f99aebeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=200000, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "en_counter = Counter()\n",
    "en_sentences=[]\n",
    "with open(\"data/parallel/IITB.en-hi.en\") as f:\n",
    "    for line in tqdm_notebook(f, total=1561840, desc=\"Reading file:\"):\n",
    "        en_sentences.append(line.strip())\n",
    "    for line in tqdm_notebook(en_sentences[:N], desc=\"Processing inputs:\"):\n",
    "        # en_sentences.append(line.strip())\n",
    "        for w in nltk.tokenize.word_tokenize(line.strip()):\n",
    "            en_counter[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34438),\n",
       " ('.', 30741),\n",
       " ('%', 25035),\n",
       " ('to', 24884),\n",
       " ('_', 24232),\n",
       " (':', 22777),\n",
       " ('s', 15453),\n",
       " ('a', 12644),\n",
       " ('not', 12292),\n",
       " ('of', 12162)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28916\n"
     ]
    }
   ],
   "source": [
    "print(len(en_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lang = Lang(en_counter, VE)\n",
    "hi_lang = Lang(hi_counter, VH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1017, 59, 24, 38]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(en_lang.encodeSentence(\"How are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you ?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lang.decodeSentence(en_lang.encodeSentence(\"How are you?\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 1221, 9, 52, 2, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hi_lang.encodeSentence(\"आप कैसे है?\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप कैसे है ?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_lang.decodeSentence((hi_lang.encodeSentence(\"आप कैसे है?\", 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained word vectors (word2vec, glove, fasttext etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Seq2Seq architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging Tip: Always keep track of tensor dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (len(en_lang.word2id), 300), dtype=tf.float32)\n",
    "hi_word_emb_matrix = tf.get_variable(\"hi_word_emb_matrix\", (len(hi_lang.word2id), 300), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "input_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_target_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "target_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add SOS or GO symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = tf.concat([tf.fill([BATCH_SIZE,1], hi_lang.isos), ph_target_ids], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)\n",
    "target_emb = tf.nn.embedding_lookup(hi_word_emb_matrix, target_ids[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50), Dimension(300)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-424709a3cd80>:1: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-20566d338e2e>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, input_emb, sequence_length=input_lens, initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(128)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(128)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.GRUCell(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection = tf.layers.Dense(len(hi_lang.word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = seq2seq.TrainingHelper(target_emb, target_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = seq2seq.BasicDecoder(decoder_cell, helper, enc_state, output_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "outputs, _, outputs_lens = seq2seq.dynamic_decode(decoder, maximum_iterations=MAX_SEQ_LEN, impute_finished=False, swap_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max_len = tf.reduce_max(outputs_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Decoder Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/while/Exit_3:0' shape=(64, 128) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the decoder_cell without dropout here.\n",
    "infer_helper = seq2seq.GreedyEmbeddingHelper(hi_word_emb_matrix, tf.fill([BATCH_SIZE, ], hi_lang.isos), hi_lang.ieos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_decoder = seq2seq.BasicDecoder(decoder_cell, infer_helper, enc_state, output_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_output = seq2seq.dynamic_decode(infer_decoder, maximum_iterations=MAX_SEQ_LEN, swap_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = tf.sequence_mask(target_lens, output_max_len, dtype=tf.float32, name='masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - weighted softmax cross entropy\n",
    "cost = tf.contrib.seq2seq.sequence_loss(\n",
    "    outputs[0],\n",
    "    target_ids[:, 1:(output_max_len + 1)],\n",
    "    masks)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "\n",
    "# Gradient Clipping\n",
    "# gradients = optimizer.compute_gradients(cost)\n",
    "# capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "# train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minibatch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = list(zip(en_sentences, hi_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('British Pound Sterling', 'ब्रिटिश पोंड स्टर्लिंगName')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_n = int(0.95*N)\n",
    "# valid_n = N - train_n\n",
    "valid_n = 1000\n",
    "train_n = N - valid_n\n",
    "# valid_n = N - train_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = parallel[:train_n]\n",
    "valid_pairs = parallel[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_test():\n",
    "    all_bleu = []\n",
    "    smoothing = nltk.translate.bleu_score.SmoothingFunction().method7\n",
    "    for m in range(0, valid_n, BATCH_SIZE):\n",
    "        # print(f\"Status: {m}/{N}\", end='\\r')\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > N:\n",
    "            # print(\"Epoch Complete...\")\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(valid_pairs[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "\n",
    "    #     target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    #     target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    #     for i in range(m, n):\n",
    "    #         b,a = hi_lang.encodeSentence2(valid_pairs[i][1], MAX_SEQ_LEN)\n",
    "    #         target_batch[i-m,:] = a\n",
    "    #         target_lens_batch[i-m] = b\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            #target_ids: target_batch,\n",
    "            #target_lens: target_lens_batch,\n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "        pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "        for k, pred_ in enumerate(pred_batch):\n",
    "            pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "            ref = valid_pairs[m+k][1]\n",
    "            _bx = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [nltk.tokenize.word_tokenize(ref)],\n",
    "                nltk.tokenize.word_tokenize(pred_s),\n",
    "                weights=(1/3,1/3,1/3),\n",
    "                smoothing_function=smoothing)\n",
    "            all_bleu.append(_bx)\n",
    "\n",
    "    print(f\"\\n\\nBLEU Score: {np.mean(all_bleu)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 6336/199000 Loss: 7.4355077743530275\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 12736/199000 Loss: 5.6901521682739265\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 19136/199000 Loss: 5.2087216377258335\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 25536/199000 Loss: 5.2628655433654785\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 31936/199000 Loss: 4.9873642921447755\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 38336/199000 Loss: 5.0791559219360355\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 44736/199000 Loss: 4.7777185440063485\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 51136/199000 Loss: 4.9013814926147465\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 57536/199000 Loss: 5.1752510070800785\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 63936/199000 Loss: 5.0818676948547365\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 70336/199000 Loss: 5.1289081573486335\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 76736/199000 Loss: 4.9690222740173345\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 83136/199000 Loss: 4.8674006462097175\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 89536/199000 Loss: 5.0300726890563965\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 95936/199000 Loss: 4.8781161308288575\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 102336/199000 Loss: 4.9768433570861825\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 108736/199000 Loss: 5.0694446563720745\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 115136/199000 Loss: 5.0948843955993655\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 121536/199000 Loss: 5.2684946060180665\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 127936/199000 Loss: 5.1348581314086915\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 134336/199000 Loss: 4.8694190979003915\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 140736/199000 Loss: 4.9250283241271975\n",
      "\n",
      "BLEU Score: 0.0003443013520227932\n",
      "\n",
      "Status: 147136/199000 Loss: 5.0487928390502935\n",
      "\n",
      "BLEU Score: 0.0003443013520227932\n",
      "\n",
      "Status: 153536/199000 Loss: 4.9022378921508795\n",
      "\n",
      "BLEU Score: 0.0003443013520227932\n",
      "\n",
      "Status: 159936/199000 Loss: 5.1487464904785165\n",
      "\n",
      "BLEU Score: 0.0006917223872038333\n",
      "\n",
      "Status: 166336/199000 Loss: 4.7516965866088875\n",
      "\n",
      "BLEU Score: 0.0010352778086335673\n",
      "\n",
      "Status: 172736/199000 Loss: 5.0637965202331545\n",
      "\n",
      "BLEU Score: 0.0010314121948822614\n",
      "\n",
      "Status: 179136/199000 Loss: 4.7576484680175785\n",
      "\n",
      "BLEU Score: 0.0010314121948822614\n",
      "\n",
      "Status: 185536/199000 Loss: 4.9366755485534675\n",
      "\n",
      "BLEU Score: 0.0024056338806011973\n",
      "\n",
      "Status: 191936/199000 Loss: 5.0679697990417485\n",
      "\n",
      "BLEU Score: 0.005161808479541682\n",
      "\n",
      "Status: 198336/199000 Loss: 4.7682881355285645\n",
      "\n",
      "BLEU Score: 0.004131142215252479\n",
      "\n",
      "Status: 198976/199000 Loss: 4.6053829193115235\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.8761940002441415\n",
      "\n",
      "BLEU Score: 0.0034042598557516243\n",
      "\n",
      "Status: 12736/199000 Loss: 4.9130940437316895\n",
      "\n",
      "BLEU Score: 0.007878211561840778\n",
      "\n",
      "Status: 19136/199000 Loss: 4.7825307846069345\n",
      "\n",
      "BLEU Score: 0.009256268913085352\n",
      "\n",
      "Status: 25536/199000 Loss: 4.9158282279968265\n",
      "\n",
      "BLEU Score: 0.00856502797245426\n",
      "\n",
      "Status: 31936/199000 Loss: 4.6069579124450685\n",
      "\n",
      "BLEU Score: 0.00787821156184078\n",
      "\n",
      "Status: 38336/199000 Loss: 4.8017234802246095\n",
      "\n",
      "BLEU Score: 0.008035391333095885\n",
      "\n",
      "Status: 44736/199000 Loss: 4.5202770233154375\n",
      "\n",
      "BLEU Score: 0.009069789338852831\n",
      "\n",
      "Status: 51136/199000 Loss: 4.5948534011840825\n",
      "\n",
      "BLEU Score: 0.008027660105593273\n",
      "\n",
      "Status: 57536/199000 Loss: 4.8064751625061035\n",
      "\n",
      "BLEU Score: 0.008078894591205015\n",
      "\n",
      "Status: 63936/199000 Loss: 4.7216677665710455\n",
      "\n",
      "BLEU Score: 0.00910969472777778\n",
      "\n",
      "Status: 70336/199000 Loss: 4.7340359687805185\n",
      "\n",
      "BLEU Score: 0.010096589989390729\n",
      "\n",
      "Status: 76736/199000 Loss: 4.5941600799560555\n",
      "\n",
      "BLEU Score: 0.010100455603142034\n",
      "\n",
      "Status: 83136/199000 Loss: 4.5050148963928225\n",
      "\n",
      "BLEU Score: 0.013536143689722935\n",
      "\n",
      "Status: 89536/199000 Loss: 4.6900973320007325\n",
      "\n",
      "BLEU Score: 0.014872617833257952\n",
      "\n",
      "Status: 95936/199000 Loss: 4.5527362823486335\n",
      "\n",
      "BLEU Score: 0.01081899467683078\n",
      "\n",
      "Status: 102336/199000 Loss: 4.6667728424072275\n",
      "\n",
      "BLEU Score: 0.01596422532223891\n",
      "\n",
      "Status: 108736/199000 Loss: 4.7296099662780765\n",
      "\n",
      "BLEU Score: 0.01797503819179981\n",
      "\n",
      "Status: 115136/199000 Loss: 4.7526469230651855\n",
      "\n",
      "BLEU Score: 0.013875833497401364\n",
      "\n",
      "Status: 121536/199000 Loss: 4.9238405227661135\n",
      "\n",
      "BLEU Score: 0.017721720168921554\n",
      "\n",
      "Status: 127936/199000 Loss: 4.7732748985290535\n",
      "\n",
      "BLEU Score: 0.020047850589421577\n",
      "\n",
      "Status: 134336/199000 Loss: 4.5234837532043465\n",
      "\n",
      "BLEU Score: 0.012624605215446972\n",
      "\n",
      "Status: 140736/199000 Loss: 4.5780038833618165\n",
      "\n",
      "BLEU Score: 0.011653293554739229\n",
      "\n",
      "Status: 147136/199000 Loss: 4.7021379470825195\n",
      "\n",
      "BLEU Score: 0.011317705620294558\n",
      "\n",
      "Status: 153536/199000 Loss: 4.5425448417663575\n",
      "\n",
      "BLEU Score: 0.012641496553869343\n",
      "\n",
      "Status: 159936/199000 Loss: 4.8032107353210455\n",
      "\n",
      "BLEU Score: 0.008549934180100157\n",
      "\n",
      "Status: 166336/199000 Loss: 4.4481348991394045\n",
      "\n",
      "BLEU Score: 0.008511130217435593\n",
      "\n",
      "Status: 172736/199000 Loss: 4.7369775772094735\n",
      "\n",
      "BLEU Score: 0.0\n",
      "\n",
      "Status: 179136/199000 Loss: 4.4757504463195885\n",
      "\n",
      "BLEU Score: 0.01131509444826444\n",
      "\n",
      "Status: 185536/199000 Loss: 4.6821012496948245\n",
      "\n",
      "BLEU Score: 0.006829664283477986\n",
      "\n",
      "Status: 191936/199000 Loss: 4.6894946098327645\n",
      "\n",
      "BLEU Score: 0.009757870125431644\n",
      "\n",
      "Status: 198336/199000 Loss: 4.5162835121154785\n",
      "\n",
      "BLEU Score: 0.008735998008450216\n",
      "\n",
      "Status: 198976/199000 Loss: 4.3330864906311035\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.6125750541687015\n",
      "\n",
      "BLEU Score: 0.010468032856719487\n",
      "\n",
      "Status: 12736/199000 Loss: 4.6543903350830085\n",
      "\n",
      "BLEU Score: 0.01275414760370645\n",
      "\n",
      "Status: 19136/199000 Loss: 4.4804992675781255\n",
      "\n",
      "BLEU Score: 0.012090269327476292\n",
      "\n",
      "Status: 25536/199000 Loss: 4.6135377883911135\n",
      "\n",
      "BLEU Score: 0.014508483922943273\n",
      "\n",
      "Status: 31936/199000 Loss: 4.3163518905639655\n",
      "\n",
      "BLEU Score: 0.015096421362799855\n",
      "\n",
      "Status: 38336/199000 Loss: 4.5404667854309085\n",
      "\n",
      "BLEU Score: 0.0165798979539619\n",
      "\n",
      "Status: 44736/199000 Loss: 4.2921009063720795\n",
      "\n",
      "BLEU Score: 0.015695009159566835\n",
      "\n",
      "Status: 51136/199000 Loss: 4.3431291580200195\n",
      "\n",
      "BLEU Score: 0.014655360366109127\n",
      "\n",
      "Status: 57536/199000 Loss: 4.4908180236816415\n",
      "\n",
      "BLEU Score: 0.017171589691519714\n",
      "\n",
      "Status: 63936/199000 Loss: 4.4051303863525395\n",
      "\n",
      "BLEU Score: 0.01933396569470793\n",
      "\n",
      "Status: 70336/199000 Loss: 4.4659080505371095\n",
      "\n",
      "BLEU Score: 0.021209387959696593\n",
      "\n",
      "Status: 76736/199000 Loss: 4.3388037681579595\n",
      "\n",
      "BLEU Score: 0.023114328864666793\n",
      "\n",
      "Status: 83136/199000 Loss: 4.1909947395324715\n",
      "\n",
      "BLEU Score: 0.022568639701520826\n",
      "\n",
      "Status: 89536/199000 Loss: 4.3637013435363775\n",
      "\n",
      "BLEU Score: 0.018244291187423788\n",
      "\n",
      "Status: 95936/199000 Loss: 4.2772431373596195\n",
      "\n",
      "BLEU Score: 0.01884130424403281\n",
      "\n",
      "Status: 102336/199000 Loss: 4.3675851821899415\n",
      "\n",
      "BLEU Score: 0.01694253474935085\n",
      "\n",
      "Status: 108736/199000 Loss: 4.4172530174255375\n",
      "\n",
      "BLEU Score: 0.016946525640724994\n",
      "\n",
      "Status: 115136/199000 Loss: 4.4119677543640145\n",
      "\n",
      "BLEU Score: 0.017641644312927748\n",
      "\n",
      "Status: 121536/199000 Loss: 4.5610365867614755\n",
      "\n",
      "BLEU Score: 0.02128638822759885\n",
      "\n",
      "Status: 127936/199000 Loss: 4.4686183929443365\n",
      "\n",
      "BLEU Score: 0.020858758150028092\n",
      "\n",
      "Status: 134336/199000 Loss: 4.2416849136352545\n",
      "\n",
      "BLEU Score: 0.020585714221222677\n",
      "\n",
      "Status: 140736/199000 Loss: 4.2699012756347665\n",
      "\n",
      "BLEU Score: 0.021086770527864555\n",
      "\n",
      "Status: 147136/199000 Loss: 4.3954720497131355\n",
      "\n",
      "BLEU Score: 0.026543101101068847\n",
      "\n",
      "Status: 153536/199000 Loss: 4.2203741073608475\n",
      "\n",
      "BLEU Score: 0.023685801138281656\n",
      "\n",
      "Status: 159936/199000 Loss: 4.5010337829589845\n",
      "\n",
      "BLEU Score: 0.02148130276306691\n",
      "\n",
      "Status: 166336/199000 Loss: 4.1534409523010255\n",
      "\n",
      "BLEU Score: 0.024272570875200926\n",
      "\n",
      "Status: 172736/199000 Loss: 4.4342274665832525\n",
      "\n",
      "BLEU Score: 0.026636590639783988\n",
      "\n",
      "Status: 179136/199000 Loss: 4.1899662017822275\n",
      "\n",
      "BLEU Score: 0.02731660922126159\n",
      "\n",
      "Status: 185536/199000 Loss: 4.4103727340698245\n",
      "\n",
      "BLEU Score: 0.024724561983189435\n",
      "\n",
      "Status: 191936/199000 Loss: 4.3604030609130865\n",
      "\n",
      "BLEU Score: 0.02240517312848667\n",
      "\n",
      "Status: 198336/199000 Loss: 4.2172670364379885\n",
      "\n",
      "BLEU Score: 0.031546017046271115\n",
      "\n",
      "Status: 198976/199000 Loss: 4.0122756958007817\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.3922915458679215\n",
      "\n",
      "BLEU Score: 0.03266728235008555\n",
      "\n",
      "Status: 12736/199000 Loss: 4.3639011383056645\n",
      "\n",
      "BLEU Score: 0.032401290709852267\n",
      "\n",
      "Status: 19136/199000 Loss: 4.2046256065368655\n",
      "\n",
      "BLEU Score: 0.030202468948559755\n",
      "\n",
      "Status: 25536/199000 Loss: 4.3592066764831544\n",
      "\n",
      "BLEU Score: 0.033962095316113404\n",
      "\n",
      "Status: 31936/199000 Loss: 4.0633811950683595\n",
      "\n",
      "BLEU Score: 0.04037246382050921\n",
      "\n",
      "Status: 38336/199000 Loss: 4.2979578971862795\n",
      "\n",
      "BLEU Score: 0.040635016860437315\n",
      "\n",
      "Status: 44736/199000 Loss: 4.0404715538024955\n",
      "\n",
      "BLEU Score: 0.03769147938337179\n",
      "\n",
      "Status: 51136/199000 Loss: 4.1084322929382326\n",
      "\n",
      "BLEU Score: 0.02995045258508199\n",
      "\n",
      "Status: 57536/199000 Loss: 4.2583222389221195\n",
      "\n",
      "BLEU Score: 0.03506351915371299\n",
      "\n",
      "Status: 63936/199000 Loss: 4.1368751525878915\n",
      "\n",
      "BLEU Score: 0.04063535051595289\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 70336/199000 Loss: 4.2576661109924323\n",
      "\n",
      "BLEU Score: 0.04365472316659568\n",
      "\n",
      "Status: 76736/199000 Loss: 4.1121530532836915\n",
      "\n",
      "BLEU Score: 0.04291873508898363\n",
      "\n",
      "Status: 83136/199000 Loss: 3.9832925796508795\n",
      "\n",
      "BLEU Score: 0.03569969387381602\n",
      "\n",
      "Status: 89536/199000 Loss: 4.1267757415771485\n",
      "\n",
      "BLEU Score: 0.04013472255860014\n",
      "\n",
      "Status: 95936/199000 Loss: 4.0549044609069825\n",
      "\n",
      "BLEU Score: 0.044543682686717864\n",
      "\n",
      "Status: 102336/199000 Loss: 4.1538600921630866\n",
      "\n",
      "BLEU Score: 0.03858414060376789\n",
      "\n",
      "Status: 108736/199000 Loss: 4.2430262565612793\n",
      "\n",
      "BLEU Score: 0.03636673210966177\n",
      "\n",
      "Status: 115136/199000 Loss: 4.1926059722900392\n",
      "\n",
      "BLEU Score: 0.03151326999504446\n",
      "\n",
      "Status: 121536/199000 Loss: 4.3281850814819344\n",
      "\n",
      "BLEU Score: 0.04965283974008179\n",
      "\n",
      "Status: 127936/199000 Loss: 4.2653760910034185\n",
      "\n",
      "BLEU Score: 0.042909629082618306\n",
      "\n",
      "Status: 134336/199000 Loss: 4.0166168212890625\n",
      "\n",
      "BLEU Score: 0.04194838987485026\n",
      "\n",
      "Status: 140736/199000 Loss: 4.0873599052429265\n",
      "\n",
      "BLEU Score: 0.0413248521793542\n",
      "\n",
      "Status: 147136/199000 Loss: 4.2512760162353522\n",
      "\n",
      "BLEU Score: 0.051191117404975145\n",
      "\n",
      "Status: 153536/199000 Loss: 4.0439515113830575\n",
      "\n",
      "BLEU Score: 0.04924614722319252\n",
      "\n",
      "Status: 159936/199000 Loss: 4.3238787651062015\n",
      "\n",
      "BLEU Score: 0.04347458018931173\n",
      "\n",
      "Status: 166336/199000 Loss: 3.9940443038940435\n",
      "\n",
      "BLEU Score: 0.045469171206399504\n",
      "\n",
      "Status: 172736/199000 Loss: 4.2179174423217775\n",
      "\n",
      "BLEU Score: 0.05491048555520649\n",
      "\n",
      "Status: 179136/199000 Loss: 4.0562167167663575\n",
      "\n",
      "BLEU Score: 0.04228510355207448\n",
      "\n",
      "Status: 185536/199000 Loss: 4.2292728424072276\n",
      "\n",
      "BLEU Score: 0.04362419314441595\n",
      "\n",
      "Status: 191936/199000 Loss: 4.1919903755187995\n",
      "\n",
      "BLEU Score: 0.04031460918831435\n",
      "\n",
      "Status: 198336/199000 Loss: 4.0653614997863775\n",
      "\n",
      "BLEU Score: 0.04983813932323122\n",
      "\n",
      "Status: 198976/199000 Loss: 3.8711493015289307\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.2997694015502935\n",
      "\n",
      "BLEU Score: 0.047092746380026855\n",
      "\n",
      "Status: 12736/199000 Loss: 4.2363562583923345\n",
      "\n",
      "BLEU Score: 0.04357111078286561\n",
      "\n",
      "Status: 19136/199000 Loss: 4.0826258659362795\n",
      "\n",
      "BLEU Score: 0.04365728212998014\n",
      "\n",
      "Status: 25536/199000 Loss: 4.2211861610412635\n",
      "\n",
      "BLEU Score: 0.04580932714025763\n",
      "\n",
      "Status: 31936/199000 Loss: 3.9430291652679443\n",
      "\n",
      "BLEU Score: 0.05618699661284663\n",
      "\n",
      "Status: 38336/199000 Loss: 4.1860880851745605\n",
      "\n",
      "BLEU Score: 0.055768846215350026\n",
      "\n",
      "Status: 44736/199000 Loss: 3.9312310218811035\n",
      "\n",
      "BLEU Score: 0.04963317084713336\n",
      "\n",
      "Status: 51136/199000 Loss: 4.0054626464843754\n",
      "\n",
      "BLEU Score: 0.0422438357105693\n",
      "\n",
      "Status: 57536/199000 Loss: 4.1082983016967775\n",
      "\n",
      "BLEU Score: 0.051547616186228495\n",
      "\n",
      "Status: 63936/199000 Loss: 4.0245332717895515\n",
      "\n",
      "BLEU Score: 0.05137768566165488\n",
      "\n",
      "Status: 70336/199000 Loss: 4.1290588378906255\n",
      "\n",
      "BLEU Score: 0.06278324712409188\n",
      "\n",
      "Status: 76736/199000 Loss: 3.9932296276092536\n",
      "\n",
      "BLEU Score: 0.055385017117964855\n",
      "\n",
      "Status: 83136/199000 Loss: 3.8805327415466316\n",
      "\n",
      "BLEU Score: 0.0508942133967852\n",
      "\n",
      "Status: 89536/199000 Loss: 3.9754168987274175\n",
      "\n",
      "BLEU Score: 0.05694192129246109\n",
      "\n",
      "Status: 95936/199000 Loss: 3.9686646461486816\n",
      "\n",
      "BLEU Score: 0.060550294698843654\n",
      "\n",
      "Status: 102336/199000 Loss: 4.0619683265686035\n",
      "\n",
      "BLEU Score: 0.041155245901533855\n",
      "\n",
      "Status: 108736/199000 Loss: 4.1418161392211913\n",
      "\n",
      "BLEU Score: 0.04233150329557474\n",
      "\n",
      "Status: 115136/199000 Loss: 4.0906052589416516\n",
      "\n",
      "BLEU Score: 0.04171637628900131\n",
      "\n",
      "Status: 121536/199000 Loss: 4.2110590934753425\n",
      "\n",
      "BLEU Score: 0.056140131395387094\n",
      "\n",
      "Status: 127936/199000 Loss: 4.1828870773315435\n",
      "\n",
      "BLEU Score: 0.05458264650717467\n",
      "\n",
      "Status: 134336/199000 Loss: 3.9311370849609375\n",
      "\n",
      "BLEU Score: 0.055140641382837724\n",
      "\n",
      "Status: 140736/199000 Loss: 3.9868001937866215\n",
      "\n",
      "BLEU Score: 0.05376288487667036\n",
      "\n",
      "Status: 147136/199000 Loss: 4.1570420265197757\n",
      "\n",
      "BLEU Score: 0.06455788959004155\n",
      "\n",
      "Status: 153536/199000 Loss: 3.9488754272460938\n",
      "\n",
      "BLEU Score: 0.060692346169461\n",
      "\n",
      "Status: 159936/199000 Loss: 4.2502751350402835\n",
      "\n",
      "BLEU Score: 0.05620368366203099\n",
      "\n",
      "Status: 166336/199000 Loss: 3.8774044513702393\n",
      "\n",
      "BLEU Score: 0.047947125142547974\n",
      "\n",
      "Status: 172736/199000 Loss: 4.0744748115539555\n",
      "\n",
      "BLEU Score: 0.06374871227257455\n",
      "\n",
      "Status: 179136/199000 Loss: 3.9669239521026617\n",
      "\n",
      "BLEU Score: 0.05227752107745829\n",
      "\n",
      "Status: 185536/199000 Loss: 4.0983910560607914\n",
      "\n",
      "BLEU Score: 0.0478166973038011\n",
      "\n",
      "Status: 191936/199000 Loss: 4.0686683654785166\n",
      "\n",
      "BLEU Score: 0.05044601857981548\n",
      "\n",
      "Status: 198336/199000 Loss: 3.9843721389770513\n",
      "\n",
      "BLEU Score: 0.05767205931387782\n",
      "\n",
      "Status: 198976/199000 Loss: 3.7830116748809814\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.2415547370910645\n",
      "\n",
      "BLEU Score: 0.05771024618453257\n",
      "\n",
      "Status: 12736/199000 Loss: 4.1679472923278815\n",
      "\n",
      "BLEU Score: 0.05987908823167052\n",
      "\n",
      "Status: 19136/199000 Loss: 4.0134496688842776\n",
      "\n",
      "BLEU Score: 0.055591583827056215\n",
      "\n",
      "Status: 25536/199000 Loss: 4.1454281806945817\n",
      "\n",
      "BLEU Score: 0.05698331648774763\n",
      "\n",
      "Status: 31936/199000 Loss: 3.8479421138763428\n",
      "\n",
      "BLEU Score: 0.06518624986602974\n",
      "\n",
      "Status: 38336/199000 Loss: 4.0860652923583982\n",
      "\n",
      "BLEU Score: 0.06046082596810143\n",
      "\n",
      "Status: 44736/199000 Loss: 3.9004416465759277\n",
      "\n",
      "BLEU Score: 0.056174542700564684\n",
      "\n",
      "Status: 51136/199000 Loss: 3.9308536052703857\n",
      "\n",
      "BLEU Score: 0.04753786639696807\n",
      "\n",
      "Status: 57536/199000 Loss: 4.0349249839782715\n",
      "\n",
      "BLEU Score: 0.051526557081538846\n",
      "\n",
      "Status: 63936/199000 Loss: 3.9227778911590576\n",
      "\n",
      "BLEU Score: 0.05520340891612996\n",
      "\n",
      "Status: 70336/199000 Loss: 4.0351438522338875\n",
      "\n",
      "BLEU Score: 0.07060459743090555\n",
      "\n",
      "Status: 76736/199000 Loss: 3.9353713989257812\n",
      "\n",
      "BLEU Score: 0.06363591628998105\n",
      "\n",
      "Status: 83136/199000 Loss: 3.7897989749908447\n",
      "\n",
      "BLEU Score: 0.05458245253361263\n",
      "\n",
      "Status: 89536/199000 Loss: 3.9127128124237065\n",
      "\n",
      "BLEU Score: 0.06161578964096031\n",
      "\n",
      "Status: 95936/199000 Loss: 3.8814017772674566\n",
      "\n",
      "BLEU Score: 0.05762174919843431\n",
      "\n",
      "Status: 102336/199000 Loss: 3.9849572181701666\n",
      "\n",
      "BLEU Score: 0.044759649819411954\n",
      "\n",
      "Status: 108736/199000 Loss: 4.0664167404174805\n",
      "\n",
      "BLEU Score: 0.0464703673214518\n",
      "\n",
      "Status: 115136/199000 Loss: 4.0201206207275393\n",
      "\n",
      "BLEU Score: 0.04753225284213416\n",
      "\n",
      "Status: 121536/199000 Loss: 4.1300568580627444\n",
      "\n",
      "BLEU Score: 0.060941508384557384\n",
      "\n",
      "Status: 127936/199000 Loss: 4.1095194816589355\n",
      "\n",
      "BLEU Score: 0.06172889745413905\n",
      "\n",
      "Status: 134336/199000 Loss: 3.8370540142059326\n",
      "\n",
      "BLEU Score: 0.05076881376785442\n",
      "\n",
      "Status: 140736/199000 Loss: 3.9138431549072266\n",
      "\n",
      "BLEU Score: 0.06085447951112201\n",
      "\n",
      "Status: 147136/199000 Loss: 4.0893015861511236\n",
      "\n",
      "BLEU Score: 0.06731581229712455\n",
      "\n",
      "Status: 153536/199000 Loss: 3.8808603286743164\n",
      "\n",
      "BLEU Score: 0.069353343360692\n",
      "\n",
      "Status: 159936/199000 Loss: 4.1547908782958985\n",
      "\n",
      "BLEU Score: 0.05673750679987467\n",
      "\n",
      "Status: 166336/199000 Loss: 3.8251461982727053\n",
      "\n",
      "BLEU Score: 0.051493512211040926\n",
      "\n",
      "Status: 172736/199000 Loss: 4.0016698837280275\n",
      "\n",
      "BLEU Score: 0.062470949539641135\n",
      "\n",
      "Status: 179136/199000 Loss: 3.9209563732147217\n",
      "\n",
      "BLEU Score: 0.052185805710558135\n",
      "\n",
      "Status: 185536/199000 Loss: 4.0115609169006356\n",
      "\n",
      "BLEU Score: 0.05140001128267082\n",
      "\n",
      "Status: 191936/199000 Loss: 3.9957351684570312\n",
      "\n",
      "BLEU Score: 0.055518687336164683\n",
      "\n",
      "Status: 198336/199000 Loss: 3.9258966445922852\n",
      "\n",
      "BLEU Score: 0.0619445109697711\n",
      "\n",
      "Status: 198976/199000 Loss: 3.7214503288269043\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.1528573036193857\n",
      "\n",
      "BLEU Score: 0.06199655807285081\n",
      "\n",
      "Status: 12736/199000 Loss: 4.1170186996459966\n",
      "\n",
      "BLEU Score: 0.0582678245543577\n",
      "\n",
      "Status: 19136/199000 Loss: 3.9587986469268815\n",
      "\n",
      "BLEU Score: 0.05596760535317127\n",
      "\n",
      "Status: 25536/199000 Loss: 4.0756907463073736\n",
      "\n",
      "BLEU Score: 0.05961632515600788\n",
      "\n",
      "Status: 31936/199000 Loss: 3.7960903644561768\n",
      "\n",
      "BLEU Score: 0.07057364862616357\n",
      "\n",
      "Status: 38336/199000 Loss: 4.0047287940979895\n",
      "\n",
      "BLEU Score: 0.06671682141155011\n",
      "\n",
      "Status: 44736/199000 Loss: 3.8065714836120605\n",
      "\n",
      "BLEU Score: 0.058462579148878945\n",
      "\n",
      "Status: 51136/199000 Loss: 3.8821384906768833\n",
      "\n",
      "BLEU Score: 0.05301814907280219\n",
      "\n",
      "Status: 57536/199000 Loss: 3.9248099327087402\n",
      "\n",
      "BLEU Score: 0.057104015346648246\n",
      "\n",
      "Status: 63936/199000 Loss: 3.8496506214141846\n",
      "\n",
      "BLEU Score: 0.05773639618194634\n",
      "\n",
      "Status: 70336/199000 Loss: 3.9442968368530273\n",
      "\n",
      "BLEU Score: 0.0737957254806841\n",
      "\n",
      "Status: 76736/199000 Loss: 3.8642287254333496\n",
      "\n",
      "BLEU Score: 0.06328391187946208\n",
      "\n",
      "Status: 83136/199000 Loss: 3.7436013221740723\n",
      "\n",
      "BLEU Score: 0.05981251309009061\n",
      "\n",
      "Status: 89536/199000 Loss: 3.8489692211151123\n",
      "\n",
      "BLEU Score: 0.06461486773254657\n",
      "\n",
      "Status: 95936/199000 Loss: 3.8178277015686035\n",
      "\n",
      "BLEU Score: 0.06218376029390217\n",
      "\n",
      "Status: 102336/199000 Loss: 3.9299249649047857\n",
      "\n",
      "BLEU Score: 0.054260083859213375\n",
      "\n",
      "Status: 108736/199000 Loss: 3.9992783069610596\n",
      "\n",
      "BLEU Score: 0.05332617118039409\n",
      "\n",
      "Status: 115136/199000 Loss: 3.9623992443084717\n",
      "\n",
      "BLEU Score: 0.054237673345936946\n",
      "\n",
      "Status: 121536/199000 Loss: 4.0815572738647463\n",
      "\n",
      "BLEU Score: 0.06368152275043668\n",
      "\n",
      "Status: 127936/199000 Loss: 4.0390920639038095\n",
      "\n",
      "BLEU Score: 0.06309600201483043\n",
      "\n",
      "Status: 134336/199000 Loss: 3.8154096603393555\n",
      "\n",
      "BLEU Score: 0.05767625113264736\n",
      "\n",
      "Status: 140736/199000 Loss: 3.8570885658264165\n",
      "\n",
      "BLEU Score: 0.05494071678088362\n",
      "\n",
      "Status: 147136/199000 Loss: 4.0441770553588876\n",
      "\n",
      "BLEU Score: 0.06582370494482219\n",
      "\n",
      "Status: 153536/199000 Loss: 3.8208315372467045\n",
      "\n",
      "BLEU Score: 0.06479572998151802\n",
      "\n",
      "Status: 159936/199000 Loss: 4.0917229652404785\n",
      "\n",
      "BLEU Score: 0.05591947601106413\n",
      "\n",
      "Status: 166336/199000 Loss: 3.7773425579071045\n",
      "\n",
      "BLEU Score: 0.055533600147566003\n",
      "\n",
      "Status: 172736/199000 Loss: 3.9001808166503906\n",
      "\n",
      "BLEU Score: 0.0640642929037529\n",
      "\n",
      "Status: 179136/199000 Loss: 3.8583106994628906\n",
      "\n",
      "BLEU Score: 0.058609137048587175\n",
      "\n",
      "Status: 185536/199000 Loss: 3.9182052612304688\n",
      "\n",
      "BLEU Score: 0.05722285467683229\n",
      "\n",
      "Status: 191936/199000 Loss: 3.9680378437042236\n",
      "\n",
      "BLEU Score: 0.05836796392743213\n",
      "\n",
      "Status: 198336/199000 Loss: 3.8476917743682865\n",
      "\n",
      "BLEU Score: 0.06477359759341365\n",
      "\n",
      "Status: 198976/199000 Loss: 3.6754555702209473\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.1050310134887695\n",
      "\n",
      "BLEU Score: 0.06494394537516421\n",
      "\n",
      "Status: 12736/199000 Loss: 4.0635061264038097\n",
      "\n",
      "BLEU Score: 0.06179987111906507\n",
      "\n",
      "Status: 19136/199000 Loss: 3.9145720005035415\n",
      "\n",
      "BLEU Score: 0.05999131448083479\n",
      "\n",
      "Status: 25536/199000 Loss: 4.0509843826293945\n",
      "\n",
      "BLEU Score: 0.05958554446686414\n",
      "\n",
      "Status: 31936/199000 Loss: 3.7433218955993652\n",
      "\n",
      "BLEU Score: 0.07588235755201261\n",
      "\n",
      "Status: 38336/199000 Loss: 3.9504477977752686\n",
      "\n",
      "BLEU Score: 0.06691905180751281\n",
      "\n",
      "Status: 44736/199000 Loss: 3.7731149196624756\n",
      "\n",
      "BLEU Score: 0.06183032146187531\n",
      "\n",
      "Status: 51136/199000 Loss: 3.8375456333160417\n",
      "\n",
      "BLEU Score: 0.057333051724587435\n",
      "\n",
      "Status: 57536/199000 Loss: 3.8752284049987793\n",
      "\n",
      "BLEU Score: 0.05993574978470142\n",
      "\n",
      "Status: 63936/199000 Loss: 3.7849953174591064\n",
      "\n",
      "BLEU Score: 0.062339748175068606\n",
      "\n",
      "Status: 70336/199000 Loss: 3.8741338253021243\n",
      "\n",
      "BLEU Score: 0.07239098716535604\n",
      "\n",
      "Status: 76736/199000 Loss: 3.7894408702850346\n",
      "\n",
      "BLEU Score: 0.06486679745156827\n",
      "\n",
      "Status: 83136/199000 Loss: 3.6907429695129395\n",
      "\n",
      "BLEU Score: 0.058417096531360735\n",
      "\n",
      "Status: 89536/199000 Loss: 3.8105602264404297\n",
      "\n",
      "BLEU Score: 0.06295426900353715\n",
      "\n",
      "Status: 95936/199000 Loss: 3.7816054821014404\n",
      "\n",
      "BLEU Score: 0.06135039819955373\n",
      "\n",
      "Status: 102336/199000 Loss: 3.8998339176177985\n",
      "\n",
      "BLEU Score: 0.06042283473113348\n",
      "\n",
      "Status: 108736/199000 Loss: 3.9423270225524902\n",
      "\n",
      "BLEU Score: 0.06003861498554552\n",
      "\n",
      "Status: 115136/199000 Loss: 3.9061756134033203\n",
      "\n",
      "BLEU Score: 0.057388566937069375\n",
      "\n",
      "Status: 121536/199000 Loss: 4.0274152755737305\n",
      "\n",
      "BLEU Score: 0.06637654196980185\n",
      "\n",
      "Status: 127936/199000 Loss: 3.9789345264434814\n",
      "\n",
      "BLEU Score: 0.06850607760906945\n",
      "\n",
      "Status: 134336/199000 Loss: 3.7290418148040775\n",
      "\n",
      "BLEU Score: 0.06289947624094046\n",
      "\n",
      "Status: 140736/199000 Loss: 3.8131194114685064\n",
      "\n",
      "BLEU Score: 0.062068643520261715\n",
      "\n",
      "Status: 147136/199000 Loss: 3.9849772453308105\n",
      "\n",
      "BLEU Score: 0.0663425105511367\n",
      "\n",
      "Status: 153536/199000 Loss: 3.7809140682220465\n",
      "\n",
      "BLEU Score: 0.06670415642841314\n",
      "\n",
      "Status: 159936/199000 Loss: 4.0410132408142096\n",
      "\n",
      "BLEU Score: 0.05999340708649317\n",
      "\n",
      "Status: 166336/199000 Loss: 3.7115597724914552\n",
      "\n",
      "BLEU Score: 0.06312416307026406\n",
      "\n",
      "Status: 172736/199000 Loss: 3.8624942302703857\n",
      "\n",
      "BLEU Score: 0.06828574805395969\n",
      "\n",
      "Status: 179136/199000 Loss: 3.8220691680908203\n",
      "\n",
      "BLEU Score: 0.06289475203476559\n",
      "\n",
      "Status: 185536/199000 Loss: 3.8619632720947266\n",
      "\n",
      "BLEU Score: 0.0657702611143745\n",
      "\n",
      "Status: 191936/199000 Loss: 3.9349024295806885\n",
      "\n",
      "BLEU Score: 0.06359918795399916\n",
      "\n",
      "Status: 198336/199000 Loss: 3.8127582073211673\n",
      "\n",
      "BLEU Score: 0.06851408012656543\n",
      "\n",
      "Status: 198976/199000 Loss: 3.6341643333435063\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.0814003944396973\n",
      "\n",
      "BLEU Score: 0.06748995259986904\n",
      "\n",
      "Status: 12736/199000 Loss: 4.0128660202026373\n",
      "\n",
      "BLEU Score: 0.0711567032245443\n",
      "\n",
      "Status: 19136/199000 Loss: 3.8636238574981697\n",
      "\n",
      "BLEU Score: 0.0674053697442371\n",
      "\n",
      "Status: 25536/199000 Loss: 3.9917590618133545\n",
      "\n",
      "BLEU Score: 0.06475528513268229\n",
      "\n",
      "Status: 31936/199000 Loss: 3.6909363269805916\n",
      "\n",
      "BLEU Score: 0.08128756581636365\n",
      "\n",
      "Status: 38336/199000 Loss: 3.9003360271453857\n",
      "\n",
      "BLEU Score: 0.07599556830737411\n",
      "\n",
      "Status: 44736/199000 Loss: 3.7339842319488525\n",
      "\n",
      "BLEU Score: 0.06952890552535457\n",
      "\n",
      "Status: 51136/199000 Loss: 3.8130037784576416\n",
      "\n",
      "BLEU Score: 0.06754685646812204\n",
      "\n",
      "Status: 57536/199000 Loss: 3.8075106143951416\n",
      "\n",
      "BLEU Score: 0.06609866948249622\n",
      "\n",
      "Status: 63936/199000 Loss: 3.7403862476348877\n",
      "\n",
      "BLEU Score: 0.07145174893924126\n",
      "\n",
      "Status: 70336/199000 Loss: 3.8096802234649666\n",
      "\n",
      "BLEU Score: 0.0770658921849216\n",
      "\n",
      "Status: 76736/199000 Loss: 3.7536094188690186\n",
      "\n",
      "BLEU Score: 0.071156746745009\n",
      "\n",
      "Status: 83136/199000 Loss: 3.6280794143676767\n",
      "\n",
      "BLEU Score: 0.06690217407760721\n",
      "\n",
      "Status: 89536/199000 Loss: 3.7346160411834717\n",
      "\n",
      "BLEU Score: 0.07436927828391268\n",
      "\n",
      "Status: 95936/199000 Loss: 3.7228980064392094\n",
      "\n",
      "BLEU Score: 0.07440395727107815\n",
      "\n",
      "Status: 102336/199000 Loss: 3.8655977249145513\n",
      "\n",
      "BLEU Score: 0.0659541125036723\n",
      "\n",
      "Status: 108736/199000 Loss: 3.9316160678863525\n",
      "\n",
      "BLEU Score: 0.06777301382967758\n",
      "\n",
      "Status: 115136/199000 Loss: 3.8597867488861084\n",
      "\n",
      "BLEU Score: 0.06805621132476831\n",
      "\n",
      "Status: 121536/199000 Loss: 4.0136127471923837\n",
      "\n",
      "BLEU Score: 0.07425083073416351\n",
      "\n",
      "Status: 127936/199000 Loss: 3.9605333805084233\n",
      "\n",
      "BLEU Score: 0.07111576675901639\n",
      "\n",
      "Status: 134336/199000 Loss: 3.7071678638458255\n",
      "\n",
      "BLEU Score: 0.06924444572918617\n",
      "\n",
      "Status: 140736/199000 Loss: 3.7507550716400146\n",
      "\n",
      "BLEU Score: 0.06869039866199171\n",
      "\n",
      "Status: 147136/199000 Loss: 3.9663891792297363\n",
      "\n",
      "BLEU Score: 0.07425831070966374\n",
      "\n",
      "Status: 153536/199000 Loss: 3.7531261444091797\n",
      "\n",
      "BLEU Score: 0.0748881820781785\n",
      "\n",
      "Status: 159936/199000 Loss: 3.9889781475067143\n",
      "\n",
      "BLEU Score: 0.06852301493730893\n",
      "\n",
      "Status: 166336/199000 Loss: 3.6766564846038828\n",
      "\n",
      "BLEU Score: 0.0649500630084774\n",
      "\n",
      "Status: 172736/199000 Loss: 3.7912561893463135\n",
      "\n",
      "BLEU Score: 0.07318348654723626\n",
      "\n",
      "Status: 179136/199000 Loss: 3.7534155845642096\n",
      "\n",
      "BLEU Score: 0.06839116911061069\n",
      "\n",
      "Status: 185536/199000 Loss: 3.7695550918579162\n",
      "\n",
      "BLEU Score: 0.06969358828743116\n",
      "\n",
      "Status: 191936/199000 Loss: 3.8820636272430425\n",
      "\n",
      "BLEU Score: 0.06905895999013693\n",
      "\n",
      "Status: 198336/199000 Loss: 3.7778871059417725\n",
      "\n",
      "BLEU Score: 0.07174248866759812\n",
      "\n",
      "Status: 198976/199000 Loss: 3.5998394489288334\n",
      "Epoch Complete...\n",
      "Status: 6336/199000 Loss: 4.0448698997497563\n",
      "\n",
      "BLEU Score: 0.07297891793343537\n",
      "\n",
      "Status: 12736/199000 Loss: 4.0118136405944825\n",
      "\n",
      "BLEU Score: 0.07152628621023549\n",
      "\n",
      "Status: 19136/199000 Loss: 3.8170759677886963\n",
      "\n",
      "BLEU Score: 0.07122770654307067\n",
      "\n",
      "Status: 25536/199000 Loss: 3.9570691585540776\n",
      "\n",
      "BLEU Score: 0.06845618499352098\n",
      "\n",
      "Status: 31936/199000 Loss: 3.6603384017944336\n",
      "\n",
      "BLEU Score: 0.08017136884685125\n",
      "\n",
      "Status: 38336/199000 Loss: 3.8650157451629647\n",
      "\n",
      "BLEU Score: 0.07555443673263879\n",
      "\n",
      "Status: 44736/199000 Loss: 3.6827175617218018\n",
      "\n",
      "BLEU Score: 0.0680798503365456\n",
      "\n",
      "Status: 51136/199000 Loss: 3.7676444053649902\n",
      "\n",
      "BLEU Score: 0.06743554801257441\n",
      "\n",
      "Status: 57536/199000 Loss: 3.7792940139770517\n",
      "\n",
      "BLEU Score: 0.0709452547464362\n",
      "\n",
      "Status: 63936/199000 Loss: 3.7128982543945312\n",
      "\n",
      "BLEU Score: 0.07676438475335265\n",
      "\n",
      "Status: 70336/199000 Loss: 3.7526078224182132\n",
      "\n",
      "BLEU Score: 0.08166864065448623\n",
      "\n",
      "Status: 76736/199000 Loss: 3.7141795158386236\n",
      "\n",
      "BLEU Score: 0.07595909641858392\n",
      "\n",
      "Status: 83136/199000 Loss: 3.5859570503234863\n",
      "\n",
      "BLEU Score: 0.0695938662923609\n",
      "\n",
      "Status: 89536/199000 Loss: 3.7146382331848145\n",
      "\n",
      "BLEU Score: 0.0734211085309757\n",
      "\n",
      "Status: 95936/199000 Loss: 3.6723392009735107\n",
      "\n",
      "BLEU Score: 0.07648934792849969\n",
      "\n",
      "Status: 102336/199000 Loss: 3.8320937156677246\n",
      "\n",
      "BLEU Score: 0.06969908413560595\n",
      "\n",
      "Status: 108736/199000 Loss: 3.8637297153472945\n",
      "\n",
      "BLEU Score: 0.068619979446159\n",
      "\n",
      "Status: 115136/199000 Loss: 3.8141887187957764\n",
      "\n",
      "BLEU Score: 0.06890356640863825\n",
      "\n",
      "Status: 121536/199000 Loss: 3.9113776683807373\n",
      "\n",
      "BLEU Score: 0.07769694086822893\n",
      "\n",
      "Status: 127936/199000 Loss: 3.9019005298614537\n",
      "\n",
      "BLEU Score: 0.07658415480774794\n",
      "\n",
      "Status: 134336/199000 Loss: 3.6434574127197266\n",
      "\n",
      "BLEU Score: 0.07150258796817119\n",
      "\n",
      "Status: 140736/199000 Loss: 3.7075455188751225\n",
      "\n",
      "BLEU Score: 0.06946536105731276\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 147136/199000 Loss: 3.9467592239379883\n",
      "\n",
      "BLEU Score: 0.07637246289450834\n",
      "\n",
      "Status: 153536/199000 Loss: 3.6941242218017585\n",
      "\n",
      "BLEU Score: 0.07578117755415989\n",
      "\n",
      "Status: 159936/199000 Loss: 3.9460370540618896\n",
      "\n",
      "BLEU Score: 0.07325970330722577\n",
      "\n",
      "Status: 166336/199000 Loss: 3.6321368217468263\n",
      "\n",
      "BLEU Score: 0.07349705639983835\n",
      "\n",
      "Status: 172736/199000 Loss: 3.7790086269378663\n",
      "\n",
      "BLEU Score: 0.07698153677829254\n",
      "\n",
      "Status: 179136/199000 Loss: 3.7270412445068365\n",
      "\n",
      "BLEU Score: 0.07593955473255308\n",
      "\n",
      "Status: 185536/199000 Loss: 3.7541911602020264\n",
      "\n",
      "BLEU Score: 0.07297186939235496\n",
      "\n",
      "Status: 191936/199000 Loss: 3.8142096996307373\n",
      "\n",
      "BLEU Score: 0.07592772760197977\n",
      "\n",
      "Status: 198336/199000 Loss: 3.7607498168945312\n",
      "\n",
      "BLEU Score: 0.07704379341765603\n",
      "\n",
      "Status: 198976/199000 Loss: 3.5271446704864552\n",
      "Epoch Complete...\n"
     ]
    }
   ],
   "source": [
    "for _e in range(10):\n",
    "    for m in range(0, train_n, BATCH_SIZE):\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > train_n:\n",
    "            print(\"\\nEpoch Complete...\")\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(train_pairs[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "\n",
    "        target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = hi_lang.encodeSentence2(train_pairs[i][1], MAX_SEQ_LEN)\n",
    "            target_batch[i-m,:] = a\n",
    "            target_lens_batch[i-m] = b\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            ph_target_ids: target_batch,\n",
    "            target_lens: target_lens_batch,\n",
    "            keep_prob: 0.8\n",
    "        }\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "        batch_loss = sess.run(cost, feed_dict=feed_dict)\n",
    "        print(f\"Epoch: {_e} >> Status: {n}/{train_n} >> Loss: {batch_loss}\", end=\"\\r\")\n",
    "        if (1 + n//BATCH_SIZE) % 100 == 0:\n",
    "            small_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLEU Score: 0.08219526058944544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "small_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'शुभारंभ'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_lang.id2word[9758]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation using BLEU scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see some real translation examples now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(s):\n",
    "    input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    b,a = en_lang.encodeSentence2(s, MAX_SEQ_LEN)\n",
    "    input_batch[0, :] = a\n",
    "    input_lens_batch[0] = b\n",
    "    \n",
    "    feed_dict={\n",
    "        input_ids: input_batch,\n",
    "        input_lens: input_lens_batch,\n",
    "        #target_ids: target_batch,\n",
    "        #target_lens: target_lens_batch,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "    pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "    pred_ = pred_batch[0]\n",
    "    pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "    # ref = valid_pairs[m+k][1]\n",
    "    return pred_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK के लिए UNK UNK के लिए UNK UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK . UNK .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Please fill in the form.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Resources\n",
    "Last but not the least, learn PyTorch also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
