{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Sentiment Analysis Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup GPU\n",
    "- On Google Colab make sure you select Python 3/GPU runtime before running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data/\n",
    "# !wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !tar -xzf data/aclImdb_v1.tar.gz -C data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bishal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, counter, vocab_size):\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.pad = \"<PAD>\"\n",
    "        self.sos = \"<SOS>\"\n",
    "        self.eos = \"<EOS>\"\n",
    "        self.unk = \"<UNK>\"\n",
    "        \n",
    "        self.ipad = 0\n",
    "        self.isos = 1\n",
    "        self.ieos = 2\n",
    "        self.iunk = 3\n",
    "        \n",
    "        self.word2id[self.pad] = 0\n",
    "        self.word2id[self.sos] = 1\n",
    "        self.word2id[self.eos] = 2\n",
    "        self.word2id[self.unk] = 3\n",
    "        \n",
    "        self.id2word[0] = self.pad\n",
    "        self.id2word[1] = self.sos\n",
    "        self.id2word[2] = self.eos\n",
    "        self.id2word[3] = self.unk\n",
    "        \n",
    "        curr_id = 4\n",
    "        for w, c in counter.most_common(vocab_size):\n",
    "            self.word2id[w] = curr_id\n",
    "            self.id2word[curr_id] = w\n",
    "            curr_id += 1\n",
    "    \n",
    "    def encodeSentence(self, wseq, max_len=-1):\n",
    "        # wseq = nltk.tokenize.word_tokenize(s.lower().strip())\n",
    "        if max_len == -1:\n",
    "            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n",
    "        else:\n",
    "            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "        \n",
    "    def encodeSentence2(self, wseq, max_len=-1):\n",
    "        # wseq = nltk.tokenize.word_tokenize(s.lower().strip()) \n",
    "        return min(max_len, len(wseq)+1), \\\n",
    "            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n",
    "                [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "    \n",
    "    def decodeSentence(self, id_seq):\n",
    "        id_seq = np.array(id_seq + [self.ieos])\n",
    "        j = np.argmax(id_seq==self.ieos)\n",
    "        s = ' '.join([self.id2word[x] for x in id_seq[:j]])\n",
    "        s = s.replace(self.unk, \"UNK\")\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTsqaGfEKyku"
   },
   "source": [
    "### Let's read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJtY9mw6Kykv"
   },
   "outputs": [],
   "source": [
    "data_folder = 'data/aclImdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJOwy_iyKyky"
   },
   "outputs": [],
   "source": [
    "rp = os.path.join(data_folder, 'train/pos')\n",
    "train_positive = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
    "rp = os.path.join(data_folder, 'train/neg')\n",
    "train_negative = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
    "\n",
    "rp = os.path.join(data_folder, 'test/pos')\n",
    "test_positive = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
    "rp = os.path.join(data_folder, 'test/neg')\n",
    "test_negative = [os.path.join(rp, f) for f in os.listdir(rp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pmq06cnLKyk7"
   },
   "source": [
    "#### Limit number of samples\n",
    "To quickly train a small model, consider setting n_train and n_test to some relatively small numbers e.g. `1000`. Set, \n",
    "`n_train = n_test = -1` to use all the samples available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kTiqMYYKyk8"
   },
   "outputs": [],
   "source": [
    "n_train = 2500\n",
    "n_test = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTY671XQKyk4"
   },
   "outputs": [],
   "source": [
    "re_html_cleaner = re.compile(r\"<.*?>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c16ebccdb8b4da1b092ddf6cd7ef287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Crunching +ve samples: ', max=2500, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c4dff1c98b40e39d0dd83c6ec8b1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Crunching -ve samples: ', max=2500, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "en_counter = Counter()\n",
    "train_data = []\n",
    "for _fname in tqdm_notebook(train_positive[:n_train], desc=\"Crunching +ve samples: \"):\n",
    "    with open(_fname) as f:\n",
    "        text = f.read().strip()\n",
    "        text = re_html_cleaner.sub(\" \", text)\n",
    "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
    "        en_counter += Counter(wseq)\n",
    "        train_data.append((wseq, 1))\n",
    "        \n",
    "for _fname in tqdm_notebook(train_negative[:n_train], desc=\"Crunching -ve samples: \"):\n",
    "    with open(_fname) as f:\n",
    "        text = f.read().strip()\n",
    "        text = re_html_cleaner.sub(\" \", text)\n",
    "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
    "        en_counter += Counter(wseq)\n",
    "        train_data.append((wseq, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17daf18f3e448dc9c5f981060d90a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Crunching +ve samples: ', max=2500, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c6873643594c99a3f3e5cc6e936546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Crunching -ve samples: ', max=2500, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for _fname in tqdm_notebook(test_positive[:n_test], desc=\"Crunching +ve samples: \"):\n",
    "    with open(_fname) as f:\n",
    "        text = f.read().strip()\n",
    "        text = re_html_cleaner.sub(\" \", text)\n",
    "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
    "        test_data.append((wseq, 1))\n",
    "        \n",
    "for _fname in tqdm_notebook(test_negative[:n_test], desc=\"Crunching -ve samples: \"):\n",
    "    with open(_fname) as f:\n",
    "        text = f.read().strip()\n",
    "        text = re_html_cleaner.sub(\" \", text)\n",
    "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
    "        test_data.append((wseq, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common en words in dataset:\n",
      " [('the', 66942), (',', 55132), ('.', 54084), ('and', 32778), ('a', 32376), ('of', 29094), ('to', 27116), ('is', 22131), ('it', 19161), ('in', 18658)]\n",
      "\n",
      "Total (en)words gathered from dataset: 46829\n"
     ]
    }
   ],
   "source": [
    "# A few sample english words\n",
    "print(\"\\nMost common en words in dataset:\\n\", en_counter.most_common(10))\n",
    "\n",
    "print(\"\\nTotal (en)words gathered from dataset:\", len(en_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lang = Lang(en_counter, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test en encoding: [127, 32, 28, 182, 59]\n",
      "Test en decoding: where are you going ?\n"
     ]
    }
   ],
   "source": [
    "wseq = nltk.tokenize.word_tokenize(\"Where are you going?\".lower())\n",
    "print(\"Test en encoding:\", en_lang.encodeSentence(wseq))\n",
    "print(\"Test en decoding:\", en_lang.decodeSentence(en_lang.encodeSentence(wseq, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RNN based Sentence Classifier architecture\n",
    "- We will implement a RNN based classifier architecture for sentiment analysis in Tensorflow r1.13.1 / r1.14\n",
    "- Debugging Tip: Always keep track of tensor dimensions!\n",
    "- **Tensorflow Computation Graph** - We will build a tf computation graph first. This is the representation used by tf for any neural network architecture. Once the computation graph is built, you can feed data to it for training or inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (V, 300), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "input_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_placeholder = tf.placeholder(tf.int32, (None,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50), Dimension(300)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-c099abfdff6c>:1: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-20566d338e2e>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, input_emb, sequence_length=input_lens, initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(128)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(128)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approaches:\n",
    "As input to the final linear layers use mean of the hidden states?\n",
    "\n",
    "or\n",
    "\n",
    "As input to the final linear layers use the last hidden state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approch 1: Take mean of enc_outputs across dimension 1\n",
    "- **IMPORTANT:** Need to **mask** the positions in input sentence that doesn't contain any inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = tf.sequence_mask(input_lens, MAX_SEQ_LEN, dtype=tf.float32, name='masks')\n",
    "class_prob = tf.nn.sigmoid(dense_layer(tf.reduce_mean(enc_outputs*masks[:, :, None], 1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(1)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approch 2: Use enc_state (final hidden state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_prob = dense_layer(enc_state) \n",
    "# class_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizers [softmax_cross_entropy]\n",
    "Note that `onehot_labels` and `logits` must have the same shape, e.g. `[batch_size, num_classes]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_placeholder.shape)\n",
    "print(class_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - softmax cross entropy\n",
    "y_ = tf.cast(y_placeholder[:, None], dtype=tf.float32)\n",
    "cost = -y_*tf.log(class_prob + 1e-12) - (1-y_)*tf.log(1-class_prob + 1e-12)\n",
    "cost = tf.reduce_mean(cost)\n",
    "# cost = tf.losses.softmax_cross_entropy(\n",
    "#     onehot_labels=tf.stack([1-y_placeholder, y_placeholder], 1), # Conversion to one-hot\n",
    "#     logits=tf.concat([1-class_prob, class_prob], -1)\n",
    "# )\n",
    "# cost = tf.losses.sigmoid_cross_entropy(\n",
    "#     y_placeholder[:, None], # Conversion to one-hot\n",
    "#     class_prob\n",
    "# )\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(config=sess_config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minibatch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_test():\n",
    "    all_true = []\n",
    "    all_preds = []\n",
    "    for m in range(0, test_n, BATCH_SIZE):\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > test_n:\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        true_class_batch = np.zeros((BATCH_SIZE))\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(train_data[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "            true_class_batch[i-m] = train_data[i][1]\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "        pred_batch = sess.run(class_prob, feed_dict=feed_dict)\n",
    "        # acc = accuracy_score(true_class_batch, pred_batch > 0.5)\n",
    "        all_true.extend(list(true_class_batch))\n",
    "        all_preds.extend(list(pred_batch[:,0]))\n",
    "    \n",
    "    all_true = np.array(all_true)\n",
    "    all_preds = np.array(all_preds)\n",
    "    prec = precision_score(all_true, all_preds > 0.5)*100\n",
    "    rec = recall_score(all_true, all_preds > 0.5)*100\n",
    "    f1 = f1_score(all_true, all_preds > 0.5)*100\n",
    "    print(f\"Precision: {prec:2.2F}, Recall: {rec:2.2F}, F1-Score: {f1:2.2F}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f60074daae494fb9c515c4caf414af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 82.05, Recall: 5.13, F1-Score: 9.65\n",
      "Precision: 91.18, Recall: 1.24, F1-Score: 2.45\n",
      "Precision: 90.76, Recall: 4.33, F1-Score: 8.26\n",
      "Precision: 88.27, Recall: 13.26, F1-Score: 23.06\n",
      "Precision: 86.42, Recall: 23.72, F1-Score: 37.22\n",
      "Precision: 82.16, Recall: 39.30, F1-Score: 53.17\n",
      "Precision: 73.32, Recall: 62.22, F1-Score: 67.32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fac9df1216a4e5cb805c99ccfeb0b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 67.75, Recall: 78.33, F1-Score: 72.66\n",
      "Precision: 74.86, Recall: 59.99, F1-Score: 66.61\n",
      "Precision: 70.30, Recall: 77.93, F1-Score: 73.92\n",
      "Precision: 75.98, Recall: 77.89, F1-Score: 76.92\n",
      "Precision: 80.80, Recall: 72.13, F1-Score: 76.22\n",
      "Precision: 77.21, Recall: 83.58, F1-Score: 80.27\n",
      "Precision: 77.70, Recall: 86.10, F1-Score: 81.69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78df136c95ab4ad8967c133d82b21025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 78.65, Recall: 89.14, F1-Score: 83.57\n",
      "Precision: 85.99, Recall: 79.41, F1-Score: 82.57\n",
      "Precision: 84.01, Recall: 86.30, F1-Score: 85.14\n",
      "Precision: 85.00, Recall: 88.30, F1-Score: 86.62\n",
      "Precision: 87.20, Recall: 88.42, F1-Score: 87.81\n",
      "Precision: 89.17, Recall: 88.38, F1-Score: 88.77\n",
      "Precision: 88.02, Recall: 91.51, F1-Score: 89.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acca3fd17ef2446fb80e74750fb0a3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 89.73, Recall: 91.67, F1-Score: 90.69\n",
      "Precision: 89.65, Recall: 91.91, F1-Score: 90.77\n",
      "Precision: 93.52, Recall: 86.14, F1-Score: 89.68\n",
      "Precision: 86.85, Recall: 95.47, F1-Score: 90.96\n",
      "Precision: 92.92, Recall: 91.39, F1-Score: 92.15\n",
      "Precision: 91.73, Recall: 94.23, F1-Score: 92.97\n",
      "Precision: 93.37, Recall: 93.63, F1-Score: 93.50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adf498c4e1a412395f382dd339dc9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.41, Recall: 93.47, F1-Score: 93.94\n",
      "Precision: 93.48, Recall: 95.39, F1-Score: 94.43\n",
      "Precision: 96.21, Recall: 90.46, F1-Score: 93.25\n",
      "Precision: 91.84, Recall: 97.43, F1-Score: 94.55\n",
      "Precision: 95.34, Recall: 95.11, F1-Score: 95.22\n",
      "Precision: 93.65, Recall: 96.91, F1-Score: 95.25\n",
      "Precision: 97.04, Recall: 94.47, F1-Score: 95.74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cafe63a147f4658ad4d7348ee248592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 96.20, Recall: 96.31, F1-Score: 96.25\n"
     ]
    }
   ],
   "source": [
    "for _e in range(10):\n",
    "    # Mix things up a bit.\n",
    "    random.shuffle(train_data)\n",
    "    pbar = tqdm_notebook(range(0, train_n, BATCH_SIZE))\n",
    "    batch_loss = 0\n",
    "    bxi = 0\n",
    "    for m in pbar:\n",
    "        n = m + BATCH_SIZE\n",
    "        if n <= train_n:\n",
    "            # print(\"Epoch Complete... \\n\")\n",
    "\n",
    "            input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "            input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "            true_class_batch = np.zeros((BATCH_SIZE))\n",
    "            for i in range(m, n):\n",
    "                b,a = en_lang.encodeSentence2(train_data[i][0], MAX_SEQ_LEN)\n",
    "                input_batch[i-m,:] = a\n",
    "                input_lens_batch[i-m] = b\n",
    "                true_class_batch[i-m] = train_data[i][1]\n",
    "\n",
    "            feed_dict={\n",
    "                input_ids: input_batch,\n",
    "                input_lens: input_lens_batch,\n",
    "                y_placeholder: true_class_batch,\n",
    "                keep_prob: 0.8 \n",
    "            }\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            batch_loss += sess.run(cost, feed_dict=feed_dict)\n",
    "            pbar.set_description(f\"Epoch: {_e} >> Loss: {batch_loss/(bxi+1):2.2F}:\")\n",
    "            bxi += 1\n",
    "            if (1 + n//BATCH_SIZE) % 10 == 0:\n",
    "                small_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
