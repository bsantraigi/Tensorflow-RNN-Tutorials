{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English to Hindi Transliteration Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NC9qqvWoJYZT"
   },
   "source": [
    "### Setup Environment\n",
    "- On Google Colab make sure you select Python 3/GPU runtime before running the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnCJOwMIJhoE"
   },
   "source": [
    "#### Choose Python 3 + GPU/CPU\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/khwGc.png\" width=\"400\"></img>\n",
    "<img src=\"https://i.stack.imgur.com/5iL6w.png\" width=\"400\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "--2019-08-10 20:10:10--  https://raw.githubusercontent.com/bsantraigi/tensorflow-seq2seq-hindi/master/data/Hindi%20-%20Word%20Transliteration%20Pairs%201.txt\n",
      "Connecting to 172.16.2.30:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 773211 (755K) [text/plain]\n",
      "Last-modified header missing -- time-stamps turned off.\n",
      "--2019-08-10 20:10:11--  https://raw.githubusercontent.com/bsantraigi/tensorflow-seq2seq-hindi/master/data/Hindi%20-%20Word%20Transliteration%20Pairs%201.txt\n",
      "Connecting to 172.16.2.30:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 773211 (755K) [text/plain]\n",
      "Saving to: ‘data/Hindi - Word Transliteration Pairs 1.txt’\n",
      "\n",
      "100%[======================================>] 7,73,211     714KB/s   in 1.1s   \n",
      "\n",
      "2019-08-10 20:10:13 (714 KB/s) - ‘data/Hindi - Word Transliteration Pairs 1.txt’ saved [773211/773211]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget -N \"https://raw.githubusercontent.com/bsantraigi/tensorflow-seq2seq-hindi/master/data/Hindi%20-%20Word%20Transliteration%20Pairs%201.txt\" -P data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bishal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Vocabulary \n",
    "* (Vocab of characters, i.e. an Alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, counter, vocab_size):\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.pad = \"<PAD>\"\n",
    "        self.sos = \"<SOS>\"\n",
    "        self.eos = \"<EOS>\"\n",
    "        self.unk = \"<UNK>\"\n",
    "        \n",
    "        self.ipad = 0\n",
    "        self.isos = 1\n",
    "        self.ieos = 2\n",
    "        self.iunk = 3\n",
    "        \n",
    "        self.word2id[self.pad] = 0\n",
    "        self.word2id[self.sos] = 1\n",
    "        self.word2id[self.eos] = 2\n",
    "        self.word2id[self.unk] = 3\n",
    "        \n",
    "        self.id2word[0] = self.pad\n",
    "        self.id2word[1] = self.sos\n",
    "        self.id2word[2] = self.eos\n",
    "        self.id2word[3] = self.unk\n",
    "        \n",
    "        curr_id = 4\n",
    "        for w, c in counter.most_common(vocab_size):\n",
    "            self.word2id[w] = curr_id\n",
    "            self.id2word[curr_id] = w\n",
    "            curr_id += 1\n",
    "            \n",
    "    def encodeSentence(self, s, max_len=-1):\n",
    "        wseq = s.lower().strip()\n",
    "        if max_len == -1:\n",
    "            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n",
    "        else:\n",
    "            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "        \n",
    "    def encodeSentence2(self, s, max_len=-1):\n",
    "        wseq = wseq = s.lower().strip()\n",
    "        return min(max_len, len(wseq)+1), \\\n",
    "            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n",
    "                [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "    \n",
    "    def decodeSentence(self, id_seq):\n",
    "        id_seq = np.array(id_seq + [self.ieos])\n",
    "        j = np.argmax(id_seq==self.ieos)\n",
    "        s = ''.join([self.id2word[x] for x in id_seq[:j]])\n",
    "        s = s.replace(self.unk, \"UNK\")\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of samples to read\n",
    "N = 30823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data files\n",
    "- Each line contains a hindi word in both English and Devnagari script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5947e9a466904f62a46e4992e7ce8689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading file:', max=30823, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb139b8583df4ba29fcabf68910d335f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=30823, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c918f27ede470fbf93feaf16f0c6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=30823, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hi_counter = Counter()\n",
    "hi_sentences=[]\n",
    "en_counter = Counter()\n",
    "en_sentences=[]\n",
    "with open(\"data/Hindi - Word Transliteration Pairs 1.txt\") as f:\n",
    "    for line in tqdm_notebook(f, total=N, desc=\"Reading file:\"):\n",
    "        en, hi = line.strip().split(\"\\t\")\n",
    "        hi_sentences.append(hi)\n",
    "        en_sentences.append(en)\n",
    "    for line in tqdm_notebook(hi_sentences, desc=\"Processing inputs:\"):\n",
    "        for w in line.strip():\n",
    "            hi_counter[w] += 1\n",
    "    for line in tqdm_notebook(en_sentences, desc=\"Processing inputs:\"):\n",
    "        for w in line.strip():\n",
    "            en_counter[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common hi characters in dataset:\n",
      " [('ा', 21123), ('र', 9205), ('े', 8100), ('न', 7225), ('ी', 6546)]\n",
      "\n",
      "Total (hi)characters gathered from dataset: 66\n",
      "\n",
      "Most common en characters in dataset:\n",
      " [('a', 57220), ('n', 15015), ('i', 14015), ('h', 13805), ('e', 12264)]\n",
      "\n",
      "Total (en)characters gathered from dataset: 27\n"
     ]
    }
   ],
   "source": [
    "# A few sample hindi characters\n",
    "print(\"Most common hi characters in dataset:\\n\", hi_counter.most_common(5))\n",
    "\n",
    "print(\"\\nTotal (hi)characters gathered from dataset:\",len(hi_counter))\n",
    "\n",
    "# A few sample english characters\n",
    "print(\"\\nMost common en characters in dataset:\\n\", en_counter.most_common(5))\n",
    "\n",
    "print(\"\\nTotal (en)characters gathered from dataset:\", len(en_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lang = Lang(en_counter, len(en_counter))\n",
    "hi_lang = Lang(hi_counter, len(hi_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test en encoding: [15, 7, 10, 13, 9, 6, 20, 4]\n",
      "Test en decoding: shukriya\n",
      "Test hindi encoding: [35, 19, 15, 22, 5, 12, 21, 4, 2, 0]\n",
      "Test hindi decoding: शुक्रिया\n"
     ]
    }
   ],
   "source": [
    "print(\"Test en encoding:\", en_lang.encodeSentence(\"Shukriya\"))\n",
    "\n",
    "print(\"Test en decoding:\", en_lang.decodeSentence(en_lang.encodeSentence(\"Shukriya\", 10)))\n",
    "\n",
    "print(\"Test hindi encoding:\", hi_lang.encodeSentence(\"शुक्रिया\", 10))\n",
    "\n",
    "print(\"Test hindi decoding:\", hi_lang.decodeSentence((hi_lang.encodeSentence(\"शुक्रिया\", 10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE = len(en_lang.word2id)\n",
    "VH = len(hi_lang.word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Seq2Seq architecture\n",
    "- We will implement a seq2seq architecture for transliteration in Tensorflow r1.13.1 / r1.14\n",
    "- Debugging Tip: Always keep track of tensor dimensions!\n",
    "- **Tensorflow Computation Graph** - We will build a tf computation graph first. This is the representation used by tf for any neural network architecture. Once the computation graph is built, you can feed data to it for training or inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (VE, 300), dtype=tf.float32)\n",
    "hi_word_emb_matrix = tf.get_variable(\"hi_word_emb_matrix\", (VH, 300), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders\n",
    "- Input to a tensorflow graph is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "input_lens = tf.placeholder(tf.int32, (None, ))\n",
    "\n",
    "ph_target_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "target_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SOS or GO symbol\n",
    "target_ids = tf.concat([tf.fill([BATCH_SIZE,1], hi_lang.isos), ph_target_ids], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)\n",
    "target_emb = tf.nn.embedding_lookup(hi_word_emb_matrix, target_ids[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(20), Dimension(300)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder - RNN based sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-73573fbda69f>:1: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.GRUCell(128) # 128 is the dimension of hidden state\n",
    "encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob) # Adding Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-1e698e82f454>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, # The encoder GRU cell\n",
    "    input_emb, # Embedded input sequence\n",
    "    sequence_length=input_lens, # Sequence lengths of individual inputs in a batch\n",
    "    initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(128)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the shape of the final hidden state\n",
    "enc_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "decoder_cell = DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder to Output Vocab Projection Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection = tf.layers.Dense(len(hi_lang.word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = seq2seq.TrainingHelper(target_emb, target_lens)\n",
    "decoder = seq2seq.BasicDecoder(decoder_cell, helper, enc_state, output_projection)\n",
    "outputs, _, outputs_lens = seq2seq.dynamic_decode(decoder, maximum_iterations=MAX_SEQ_LEN, \n",
    "                                                  impute_finished=False, swap_memory=True)\n",
    "output_max_len = tf.reduce_max(outputs_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Decoder Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the decoder_cell without dropout here.\n",
    "infer_helper = seq2seq.GreedyEmbeddingHelper(hi_word_emb_matrix, tf.fill([BATCH_SIZE, ], hi_lang.isos), hi_lang.ieos)\n",
    "infer_decoder = seq2seq.BasicDecoder(decoder_cell, infer_helper, enc_state, output_projection)\n",
    "infer_output = seq2seq.dynamic_decode(infer_decoder, maximum_iterations=MAX_SEQ_LEN, swap_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence mask:\n",
    "# To make sure we don't back-propagate error from output of length positions\n",
    "masks = tf.sequence_mask(target_lens, output_max_len, dtype=tf.float32, name='masks')\n",
    "\n",
    "# Loss function - weighted softmax cross entropy\n",
    "cost = seq2seq.sequence_loss(\n",
    "    outputs[0],\n",
    "    target_ids[:, 1:(output_max_len + 1)],\n",
    "    masks)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=sess_config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minibatch Training + Validation\n",
    "- Performance Evaluation using BLEU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = list(zip(en_sentences, hi_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hazaarii', 'हज़ारी')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(0.95*N)\n",
    "valid_n = N - train_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = parallel[:train_n].copy()\n",
    "valid_pairs = parallel[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_test():\n",
    "    all_bleu = []\n",
    "    smoothing = nltk.translate.bleu_score.SmoothingFunction().method7\n",
    "    for m in range(0, valid_n, BATCH_SIZE):\n",
    "        # print(f\"Status: {m}/{N}\", end='\\r')\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > valid_n:\n",
    "            # print(\"Epoch Complete...\")\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(valid_pairs[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "\n",
    "    #     target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    #     target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    #     for i in range(m, n):\n",
    "    #         b,a = hi_lang.encodeSentence2(valid_pairs[i][1], MAX_SEQ_LEN)\n",
    "    #         target_batch[i-m,:] = a\n",
    "    #         target_lens_batch[i-m] = b\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            #target_ids: target_batch,\n",
    "            #target_lens: target_lens_batch,\n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "        pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "        for k, pred_ in enumerate(pred_batch):\n",
    "            pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "            ref = valid_pairs[m+k][1]\n",
    "            try:\n",
    "                _bx = nltk.translate.bleu_score.sentence_bleu(\n",
    "                    [ref],\n",
    "                    pred_s,\n",
    "                    weights=[1/4]*4,\n",
    "                    smoothing_function=smoothing)\n",
    "            except ZeroDivisionError:\n",
    "                _bx = 0\n",
    "            all_bleu.append(_bx)\n",
    "\n",
    "    print(f\"BLEU Score: {np.mean(all_bleu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da17e6a932a545b39e61b937905bf46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0015061993386807583\n",
      "BLEU Score: 0.0756992159142849\n",
      "BLEU Score: 0.11290282133985885\n",
      "BLEU Score: 0.1480994476210965\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292b4d11c0294e25a79758ac51577305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.17741847340520875\n",
      "BLEU Score: 0.20143572913574212\n",
      "BLEU Score: 0.225850697824437\n",
      "BLEU Score: 0.24425789422241562\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f62714885e465285e8d9082c41b05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.2702637237574262\n",
      "BLEU Score: 0.27688065468553885\n",
      "BLEU Score: 0.28448192820817686\n",
      "BLEU Score: 0.29224617674564873\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2df59f776e49b79ff97ebfe27ae188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.2955896506242449\n",
      "BLEU Score: 0.3049866056279527\n",
      "BLEU Score: 0.3131800838133849\n",
      "BLEU Score: 0.3155126897395858\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33824c8562241f691eb9047da309b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.32238241621712843\n",
      "BLEU Score: 0.32598394843649525\n",
      "BLEU Score: 0.33359196257610946\n",
      "BLEU Score: 0.3367758259960741\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcec9efe94b4aa4871ce7bc099a7be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.3408982204962636\n",
      "BLEU Score: 0.34800693403032473\n",
      "BLEU Score: 0.35211654678932797\n",
      "BLEU Score: 0.35554945256556186\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e4566b5e7a4d34b51829bbd6285289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.3597034744243097\n",
      "BLEU Score: 0.36671307049248375\n",
      "BLEU Score: 0.3743063552840495\n",
      "BLEU Score: 0.37238000489145767\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc40ff9c0e6440a937abf700617e0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.38319680082542246\n",
      "BLEU Score: 0.387081443469489\n",
      "BLEU Score: 0.3953301464867142\n",
      "BLEU Score: 0.3982930065409335\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901f3114dfcc4162b0cbc86bc39dde0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.4065090282232944\n",
      "BLEU Score: 0.4065919878861097\n",
      "BLEU Score: 0.4165467530968747\n",
      "BLEU Score: 0.4220703383526825\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c0cf55523b475685f6a5e0029ea7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.4364255747615051\n",
      "BLEU Score: 0.4321859748691392\n",
      "BLEU Score: 0.44008406598215427\n",
      "BLEU Score: 0.44650258614854427\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa718f4a5024e38b938b723ad576ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.4516814335584471\n",
      "BLEU Score: 0.4571410556756866\n",
      "BLEU Score: 0.46497816114990914\n",
      "BLEU Score: 0.47228449351140167\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a072ace26554de996d3b46d3e666811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.47588356199283927\n",
      "BLEU Score: 0.4831094444304529\n",
      "BLEU Score: 0.4947245844890722\n",
      "BLEU Score: 0.5005418362026622\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388bb3d67e84542b78d296decef9526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.5065003609708242\n",
      "BLEU Score: 0.5147856262276642\n",
      "BLEU Score: 0.5173945420158459\n",
      "BLEU Score: 0.5219696399488596\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8914860d954643e48b87c2d8fc18010b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.5305935969072456\n",
      "BLEU Score: 0.5360337338370235\n",
      "BLEU Score: 0.537999443167081\n",
      "BLEU Score: 0.5369601059674411\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5d364a3c9641c8a11cf6bf403ace78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.55592397617134\n",
      "BLEU Score: 0.55526547009493\n",
      "BLEU Score: 0.5648444974749984\n",
      "BLEU Score: 0.5614916010716291\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a2553134224d24978b2fd7380b6705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.5741181475566096\n",
      "BLEU Score: 0.5728622910105807\n",
      "BLEU Score: 0.5746241008173437\n",
      "BLEU Score: 0.579336187101691\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949eb8c9d917433692fdddaeaca0a325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.5833458220737976\n",
      "BLEU Score: 0.5881732231529364\n",
      "BLEU Score: 0.589651475966446\n",
      "BLEU Score: 0.5971149939231034\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c2d091916e48ce9de9e13c9b151689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.5959277935244045\n",
      "BLEU Score: 0.600261646326761\n",
      "BLEU Score: 0.6043983185238346\n",
      "BLEU Score: 0.6094852585790623\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb483f5f8b714457abe77cd01599d492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.610158884519212\n",
      "BLEU Score: 0.6146452675497532\n",
      "BLEU Score: 0.6058223461268137\n",
      "BLEU Score: 0.6131855443159836\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1463527c5b40d7a6095751db459658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.6182856361594138\n",
      "BLEU Score: 0.620302774263697\n",
      "BLEU Score: 0.6255745267126785\n",
      "BLEU Score: 0.6288471674183466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _e in range(20):\n",
    "    # Mix things up a bit.\n",
    "    random.shuffle(train_pairs)\n",
    "    pbar = tqdm_notebook(range(0, train_n, BATCH_SIZE))\n",
    "    batch_loss = 0\n",
    "    bxi = 0\n",
    "    for m in pbar:\n",
    "        n = m + BATCH_SIZE\n",
    "        if n <= train_n:\n",
    "            # print(\"Epoch Complete... \\n\")\n",
    "\n",
    "            input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "            input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "            for i in range(m, n):\n",
    "                b,a = en_lang.encodeSentence2(train_pairs[i][0], MAX_SEQ_LEN)\n",
    "                input_batch[i-m,:] = a\n",
    "                input_lens_batch[i-m] = b\n",
    "\n",
    "            target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "            target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "            for i in range(m, n):\n",
    "                b,a = hi_lang.encodeSentence2(train_pairs[i][1], MAX_SEQ_LEN)\n",
    "                target_batch[i-m,:] = a\n",
    "                target_lens_batch[i-m] = b\n",
    "\n",
    "            feed_dict={\n",
    "                input_ids: input_batch,\n",
    "                input_lens: input_lens_batch,\n",
    "                ph_target_ids: target_batch,\n",
    "                target_lens: target_lens_batch,\n",
    "                keep_prob: 0.8 \n",
    "            }\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            batch_loss += sess.run(cost, feed_dict=feed_dict)\n",
    "            pbar.set_description(f\"Epoch: {_e} >> Loss: {batch_loss/(bxi+1):2.2F}:\")\n",
    "            bxi += 1\n",
    "            if (1 + n//BATCH_SIZE) % 100 == 0:\n",
    "                small_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see some real translation examples now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate(s):\n",
    "    input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    b,a = en_lang.encodeSentence2(s, MAX_SEQ_LEN)\n",
    "    input_batch[0, :] = a\n",
    "    input_lens_batch[0] = b\n",
    "    \n",
    "    feed_dict={\n",
    "        input_ids: input_batch,\n",
    "        input_lens: input_lens_batch,\n",
    "        #target_ids: target_batch,\n",
    "        #target_lens: target_lens_batch,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "    pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "    pred_ = pred_batch[0]\n",
    "    pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "    # ref = valid_pairs[m+k][1]\n",
    "    return pred_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'साया'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"saya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'रामा'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"raama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'शाहर'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"shahar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
