{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bishal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, counter, vocab_size):\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.pad = \"<PAD>\"\n",
    "        self.sos = \"<SOS>\"\n",
    "        self.eos = \"<EOS>\"\n",
    "        self.unk = \"<UNK>\"\n",
    "        \n",
    "        self.ipad = 0\n",
    "        self.isos = 1\n",
    "        self.ieos = 2\n",
    "        self.iunk = 3\n",
    "        \n",
    "        self.word2id[self.pad] = 0\n",
    "        self.word2id[self.sos] = 1\n",
    "        self.word2id[self.eos] = 2\n",
    "        self.word2id[self.unk] = 3\n",
    "        \n",
    "        self.id2word[0] = self.pad\n",
    "        self.id2word[1] = self.sos\n",
    "        self.id2word[2] = self.eos\n",
    "        self.id2word[3] = self.unk\n",
    "        \n",
    "        curr_id = 4\n",
    "        for w, c in counter.most_common(vocab_size):\n",
    "            self.word2id[w] = curr_id\n",
    "            self.id2word[curr_id] = w\n",
    "            curr_id += 1\n",
    "            \n",
    "    def encodeSentence(self, s, max_len=-1):\n",
    "        wseq = s.lower().strip()\n",
    "        if max_len == -1:\n",
    "            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n",
    "        else:\n",
    "            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "        \n",
    "    def encodeSentence2(self, s, max_len=-1):\n",
    "        wseq = wseq = s.lower().strip()\n",
    "        return min(max_len, len(wseq)+1), \\\n",
    "            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n",
    "                [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
    "    \n",
    "    def decodeSentence(self, id_seq):\n",
    "        id_seq = np.array(id_seq + [self.ieos])\n",
    "        j = np.argmax(id_seq==self.ieos)\n",
    "        s = ''.join([self.id2word[x] for x in id_seq[:j]])\n",
    "        s = s.replace(self.unk, \"UNK\")\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f541fd7406e54b328da5002f2e8778cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Reading file:', max=30823, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28e0e88b66a42818cce2207035ed202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=30823, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd877b209c644b0ebc892597beae5d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing inputs:', max=30823, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hi_counter = Counter()\n",
    "hi_sentences=[]\n",
    "en_counter = Counter()\n",
    "en_sentences=[]\n",
    "with open(\"data/Hindi - Word Transliteration Pairs 1.txt\") as f:\n",
    "    for line in tqdm_notebook(f, total=N, desc=\"Reading file:\"):\n",
    "        en, hi = line.strip().split(\"\\t\")\n",
    "        hi_sentences.append(hi)\n",
    "        en_sentences.append(en)\n",
    "    for line in tqdm_notebook(hi_sentences, desc=\"Processing inputs:\"):\n",
    "        for w in line.strip():\n",
    "            hi_counter[w] += 1\n",
    "    for line in tqdm_notebook(en_sentences, desc=\"Processing inputs:\"):\n",
    "        for w in line.strip():\n",
    "            en_counter[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ा', 21123),\n",
       " ('र', 9205),\n",
       " ('े', 8100),\n",
       " ('न', 7225),\n",
       " ('ी', 6546),\n",
       " ('ल', 6434),\n",
       " ('ं', 5748),\n",
       " ('म', 5707),\n",
       " ('ि', 5602),\n",
       " ('त', 5571)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(hi_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 57220),\n",
       " ('n', 15015),\n",
       " ('i', 14015),\n",
       " ('h', 13805),\n",
       " ('e', 12264),\n",
       " ('r', 9262),\n",
       " ('u', 8539),\n",
       " ('t', 7181),\n",
       " ('o', 6691),\n",
       " ('k', 6498)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(en_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lang = Lang(en_counter, len(en_counter))\n",
    "hi_lang = Lang(hi_counter, len(hi_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 7, 10, 13, 9, 6, 20, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(en_lang.encodeSentence(\"Shukriya\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shukriya'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lang.decodeSentence(en_lang.encodeSentence(\"Shukriya\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 19, 15, 22, 5, 12, 21, 4, 2, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hi_lang.encodeSentence(\"शुक्रिया\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'शुक्रिया'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_lang.decodeSentence((hi_lang.encodeSentence(\"शुक्रिया\", 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE = len(en_lang.word2id)\n",
    "VH = len(hi_lang.word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained word vectors (word2vec, glove, fasttext etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Seq2Seq architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging Tip: Always keep track of tensor dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (VE, 300), dtype=tf.float32)\n",
    "hi_word_emb_matrix = tf.get_variable(\"hi_word_emb_matrix\", (VH, 300), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "input_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_target_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
    "target_lens = tf.placeholder(tf.int32, (None, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SOS or GO symbol\n",
    "target_ids = tf.concat([tf.fill([BATCH_SIZE,1], hi_lang.isos), ph_target_ids], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)\n",
    "target_emb = tf.nn.embedding_lookup(hi_word_emb_matrix, target_ids[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(20), Dimension(300)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-c099abfdff6c>:1: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-20566d338e2e>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/bishal/miniconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, input_emb, sequence_length=input_lens, initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(20), Dimension(128)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(128)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "decoder_cell = DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection = tf.layers.Dense(len(hi_lang.word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = seq2seq.TrainingHelper(target_emb, target_lens)\n",
    "decoder = seq2seq.BasicDecoder(decoder_cell, helper, enc_state, output_projection)\n",
    "outputs, _, outputs_lens = seq2seq.dynamic_decode(decoder, maximum_iterations=MAX_SEQ_LEN, \n",
    "                                                  impute_finished=False, swap_memory=True)\n",
    "output_max_len = tf.reduce_max(outputs_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Decoder Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the decoder_cell without dropout here.\n",
    "infer_helper = seq2seq.GreedyEmbeddingHelper(hi_word_emb_matrix, tf.fill([BATCH_SIZE, ], hi_lang.isos), hi_lang.ieos)\n",
    "infer_decoder = seq2seq.BasicDecoder(decoder_cell, infer_helper, enc_state, output_projection)\n",
    "infer_output = seq2seq.dynamic_decode(infer_decoder, maximum_iterations=MAX_SEQ_LEN, swap_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = tf.sequence_mask(target_lens, output_max_len, dtype=tf.float32, name='masks')\n",
    "\n",
    "# Loss function - weighted softmax cross entropy\n",
    "cost = tf.contrib.seq2seq.sequence_loss(\n",
    "    outputs[0],\n",
    "    target_ids[:, 1:(output_max_len + 1)],\n",
    "    masks)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "\n",
    "# Gradient Clipping\n",
    "# gradients = optimizer.compute_gradients(cost)\n",
    "# capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "# train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=sess_config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minibatch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = list(zip(en_sentences, hi_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hazaarii', 'हज़ारी')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(0.95*N)\n",
    "valid_n = N - train_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = parallel[:train_n]\n",
    "valid_pairs = parallel[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_test():\n",
    "    all_bleu = []\n",
    "    smoothing = nltk.translate.bleu_score.SmoothingFunction().method7\n",
    "    for m in range(0, valid_n, BATCH_SIZE):\n",
    "        # print(f\"Status: {m}/{N}\", end='\\r')\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > valid_n:\n",
    "            # print(\"Epoch Complete...\")\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(valid_pairs[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "\n",
    "    #     target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    #     target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    #     for i in range(m, n):\n",
    "    #         b,a = hi_lang.encodeSentence2(valid_pairs[i][1], MAX_SEQ_LEN)\n",
    "    #         target_batch[i-m,:] = a\n",
    "    #         target_lens_batch[i-m] = b\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            #target_ids: target_batch,\n",
    "            #target_lens: target_lens_batch,\n",
    "            keep_prob: 1.0\n",
    "        }\n",
    "        pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "        for k, pred_ in enumerate(pred_batch):\n",
    "            pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "            ref = valid_pairs[m+k][1]\n",
    "            try:\n",
    "                _bx = nltk.translate.bleu_score.sentence_bleu(\n",
    "                    [ref],\n",
    "                    pred_s,\n",
    "                    weights=[1/4]*4,\n",
    "                    smoothing_function=smoothing)\n",
    "            except ZeroDivisionError:\n",
    "                _bx = 0\n",
    "            all_bleu.append(_bx)\n",
    "\n",
    "    print(f\"\\n\\nBLEU Score: {np.mean(all_bleu)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 >> Status: 6336/29281 >> Loss: 0.9172216057777405\n",
      "\n",
      "BLEU Score: 0.4724988605397558\n",
      "\n",
      "Epoch: 0 >> Status: 12736/29281 >> Loss: 0.9279507398605347\n",
      "\n",
      "BLEU Score: 0.48221586559038104\n",
      "\n",
      "Epoch: 0 >> Status: 19136/29281 >> Loss: 0.9116573929786682\n",
      "\n",
      "BLEU Score: 0.48318973653939395\n",
      "\n",
      "Epoch: 0 >> Status: 25536/29281 >> Loss: 0.8010704517364502\n",
      "\n",
      "BLEU Score: 0.49410303340931244\n",
      "\n",
      "Epoch: 0 >> Status: 29248/29281 >> Loss: 0.8818286657333374\n",
      "Epoch Complete...\n",
      "Epoch: 1 >> Status: 6336/29281 >> Loss: 0.8470025658607483\n",
      "\n",
      "BLEU Score: 0.4965431799164603\n",
      "\n",
      "Epoch: 1 >> Status: 12736/29281 >> Loss: 0.8599395155906677\n",
      "\n",
      "BLEU Score: 0.5058346841913631\n",
      "\n",
      "Epoch: 1 >> Status: 19136/29281 >> Loss: 0.8254892230033875\n",
      "\n",
      "BLEU Score: 0.5091217964978457\n",
      "\n",
      "Epoch: 1 >> Status: 25536/29281 >> Loss: 0.7479752898216248\n",
      "\n",
      "BLEU Score: 0.5149384027416605\n",
      "\n",
      "Epoch: 1 >> Status: 29248/29281 >> Loss: 0.8322769403457642\n",
      "Epoch Complete...\n",
      "Epoch: 2 >> Status: 6336/29281 >> Loss: 0.7693257331848145\n",
      "\n",
      "BLEU Score: 0.5230378639120795\n",
      "\n",
      "Epoch: 2 >> Status: 12736/29281 >> Loss: 0.8012828826904297\n",
      "\n",
      "BLEU Score: 0.5311247094610422\n",
      "\n",
      "Epoch: 2 >> Status: 19136/29281 >> Loss: 0.8057855367660522\n",
      "\n",
      "BLEU Score: 0.5348857106530309\n",
      "\n",
      "Epoch: 2 >> Status: 25536/29281 >> Loss: 0.7155976891517639\n",
      "\n",
      "BLEU Score: 0.5384260845845371\n",
      "\n",
      "Epoch: 2 >> Status: 29248/29281 >> Loss: 0.7962764501571655\n",
      "Epoch Complete...\n",
      "Epoch: 3 >> Status: 6336/29281 >> Loss: 0.7234537601470947\n",
      "\n",
      "BLEU Score: 0.5441478045622917\n",
      "\n",
      "Epoch: 3 >> Status: 12736/29281 >> Loss: 0.7616723179817282\n",
      "\n",
      "BLEU Score: 0.5467362299648767\n",
      "\n",
      "Epoch: 3 >> Status: 19136/29281 >> Loss: 0.7533681392669678\n",
      "\n",
      "BLEU Score: 0.5603060924117661\n",
      "\n",
      "Epoch: 3 >> Status: 25536/29281 >> Loss: 0.6695241332054138\n",
      "\n",
      "BLEU Score: 0.5608625366630903\n",
      "\n",
      "Epoch: 3 >> Status: 29248/29281 >> Loss: 0.7362521886825562\n",
      "Epoch Complete...\n",
      "Epoch: 4 >> Status: 6336/29281 >> Loss: 0.6952254176139832\n",
      "\n",
      "BLEU Score: 0.5612199106277976\n",
      "\n",
      "Epoch: 4 >> Status: 12736/29281 >> Loss: 0.7124413847923279\n",
      "\n",
      "BLEU Score: 0.5655087234496744\n",
      "\n",
      "Epoch: 4 >> Status: 19136/29281 >> Loss: 0.6920844912528992\n",
      "\n",
      "BLEU Score: 0.5750574459663454\n",
      "\n",
      "Epoch: 4 >> Status: 25536/29281 >> Loss: 0.6192373037338257\n",
      "\n",
      "BLEU Score: 0.5764393419931998\n",
      "\n",
      "Epoch: 4 >> Status: 29248/29281 >> Loss: 0.6933982968330383\n",
      "Epoch Complete...\n",
      "Epoch: 5 >> Status: 6336/29281 >> Loss: 0.6487503647804267\n",
      "\n",
      "BLEU Score: 0.5801628898360023\n",
      "\n",
      "Epoch: 5 >> Status: 12736/29281 >> Loss: 0.6730658411979675\n",
      "\n",
      "BLEU Score: 0.583956629333329\n",
      "\n",
      "Epoch: 5 >> Status: 19136/29281 >> Loss: 0.6601386666297913\n",
      "\n",
      "BLEU Score: 0.5877096256483149\n",
      "\n",
      "Epoch: 5 >> Status: 25536/29281 >> Loss: 0.5934037566184998\n",
      "\n",
      "BLEU Score: 0.5907869069576686\n",
      "\n",
      "Epoch: 5 >> Status: 29248/29281 >> Loss: 0.6576459407806396\n",
      "Epoch Complete...\n",
      "Epoch: 6 >> Status: 6336/29281 >> Loss: 0.6263318657875061\n",
      "\n",
      "BLEU Score: 0.5905533020940715\n",
      "\n",
      "Epoch: 6 >> Status: 12736/29281 >> Loss: 0.6141638755798349\n",
      "\n",
      "BLEU Score: 0.5954623253403214\n",
      "\n",
      "Epoch: 6 >> Status: 19136/29281 >> Loss: 0.6731541156768799\n",
      "\n",
      "BLEU Score: 0.6002843113864401\n",
      "\n",
      "Epoch: 6 >> Status: 25536/29281 >> Loss: 0.5786415934562683\n",
      "\n",
      "BLEU Score: 0.6061990508634282\n",
      "\n",
      "Epoch: 6 >> Status: 29248/29281 >> Loss: 0.63376504182815555\n",
      "Epoch Complete...\n",
      "Epoch: 7 >> Status: 6336/29281 >> Loss: 0.58930647373199466\n",
      "\n",
      "BLEU Score: 0.6069639961382864\n",
      "\n",
      "Epoch: 7 >> Status: 12736/29281 >> Loss: 0.5821357369422913\n",
      "\n",
      "BLEU Score: 0.6112519925174489\n",
      "\n",
      "Epoch: 7 >> Status: 19136/29281 >> Loss: 0.5955452919006348\n",
      "\n",
      "BLEU Score: 0.6120683050525206\n",
      "\n",
      "Epoch: 7 >> Status: 25536/29281 >> Loss: 0.5279858708381653\n",
      "\n",
      "BLEU Score: 0.6161728266816177\n",
      "\n",
      "Epoch: 7 >> Status: 29248/29281 >> Loss: 0.63557201623916633\n",
      "Epoch Complete...\n",
      "Epoch: 8 >> Status: 6336/29281 >> Loss: 0.56020271778106697\n",
      "\n",
      "BLEU Score: 0.6196102877825402\n",
      "\n",
      "Epoch: 8 >> Status: 12736/29281 >> Loss: 0.5654244422912598\n",
      "\n",
      "BLEU Score: 0.6232164337070772\n",
      "\n",
      "Epoch: 8 >> Status: 19136/29281 >> Loss: 0.60215228796005257\n",
      "\n",
      "BLEU Score: 0.6209831258461977\n",
      "\n",
      "Epoch: 8 >> Status: 25536/29281 >> Loss: 0.5187546610832214\n",
      "\n",
      "BLEU Score: 0.6264624549716573\n",
      "\n",
      "Epoch: 8 >> Status: 29248/29281 >> Loss: 0.62410837411880497\n",
      "Epoch Complete...\n",
      "Epoch: 9 >> Status: 6336/29281 >> Loss: 0.5336390733718872\n",
      "\n",
      "BLEU Score: 0.6260719485122893\n",
      "\n",
      "Epoch: 9 >> Status: 10624/29281 >> Loss: 0.5730058550834656\r"
     ]
    }
   ],
   "source": [
    "for _e in range(20):\n",
    "    for m in range(0, train_n, BATCH_SIZE):\n",
    "        n = m + BATCH_SIZE\n",
    "        if n > train_n:\n",
    "            print(\"\\nEpoch Complete...\")\n",
    "            break\n",
    "\n",
    "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = en_lang.encodeSentence2(train_pairs[i][0], MAX_SEQ_LEN)\n",
    "            input_batch[i-m,:] = a\n",
    "            input_lens_batch[i-m] = b\n",
    "\n",
    "        target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "        target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "        for i in range(m, n):\n",
    "            b,a = hi_lang.encodeSentence2(train_pairs[i][1], MAX_SEQ_LEN)\n",
    "            target_batch[i-m,:] = a\n",
    "            target_lens_batch[i-m] = b\n",
    "\n",
    "        feed_dict={\n",
    "            input_ids: input_batch,\n",
    "            input_lens: input_lens_batch,\n",
    "            ph_target_ids: target_batch,\n",
    "            target_lens: target_lens_batch,\n",
    "            keep_prob: 0.8 \n",
    "        }\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "        batch_loss = sess.run(cost, feed_dict=feed_dict)\n",
    "        print(f\"Epoch: {_e} >> Status: {n}/{train_n} >> Loss: {batch_loss}\", end=\"\\r\")\n",
    "        if (1 + n//BATCH_SIZE) % 100 == 0:\n",
    "            small_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation using BLEU scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see some real translation examples now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(s):\n",
    "    input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
    "    input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
    "    b,a = en_lang.encodeSentence2(s, MAX_SEQ_LEN)\n",
    "    input_batch[0, :] = a\n",
    "    input_lens_batch[0] = b\n",
    "    \n",
    "    feed_dict={\n",
    "        input_ids: input_batch,\n",
    "        input_lens: input_lens_batch,\n",
    "        #target_ids: target_batch,\n",
    "        #target_lens: target_lens_batch,\n",
    "        keep_prob: 1.0\n",
    "    }\n",
    "    pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n",
    "    pred_ = pred_batch[0]\n",
    "    pred_s = hi_lang.decodeSentence(list(pred_))\n",
    "    # ref = valid_pairs[m+k][1]\n",
    "    return pred_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'समा'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"gambhir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Resources\n",
    "Last but not the least, learn PyTorch also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
